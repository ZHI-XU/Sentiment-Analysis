{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "name": "BiLSTM_SST.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwcXt_Kcne5N"
   },
   "source": [
    "# LSTM_SST\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tq9imcf0ne5o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552477149,
     "user_tz": -480,
     "elapsed": 3520,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Add,\n",
    "    Lambda,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    LSTM,\n",
    "    Bidirectional\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.backend import l2_normalize\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from IPython.display import SVG"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q_GjM47tne5r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552493112,
     "user_tz": -480,
     "elapsed": 19248,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/Sentiment Analysis/SST-2/train.csv\", header=None, sep=\"\\t\", names=[\"label\", \"text\"]\n",
    ")\n",
    "dev_df = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/Sentiment Analysis/SST-2/dev.csv\", header=None, sep=\"\\t\", names=[\"label\", \"text\"]\n",
    ")\n",
    "test_df = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/Sentiment Analysis/SST-2/test.csv\", header=None, sep=\"\\t\", names=[\"label\", \"text\"]\n",
    ")\n",
    "\n",
    "\n",
    "def ModiData(obj_df):\n",
    "    obj_df = obj_df[obj_df[\"label\"] != 2]\n",
    "    # obj_df[\"label\"] = obj_df[\"label\"].astype(string)\n",
    "    obj_df.label = obj_df.label.replace(0, \"neg\")\n",
    "    obj_df.label = obj_df.label.replace(1, \"neg\")\n",
    "    obj_df.label = obj_df.label.replace(3, \"pos\")\n",
    "    obj_df.label = obj_df.label.replace(4, \"pos\")\n",
    "    obj_df = obj_df.fillna(0)\n",
    "    # obj_df[\"label\"] = obj_df[\"label\"].astype(int)\n",
    "    return obj_df\n",
    "\n",
    "\n",
    "def clean_line(line):\n",
    "    # split into tokens by white space\n",
    "    tokens = line.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding=\"post\")\n",
    "    return padded"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoxxs-jane5t",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552494932,
     "user_tz": -480,
     "elapsed": 20866,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "f6354285-c51d-4b46-c959-edfa2b3d1d30"
   },
   "source": [
    "train_df = ModiData(train_df)\n",
    "dev_df = ModiData(dev_df)\n",
    "test_df = ModiData(test_df)\n",
    "\n",
    "train_x = train_df.text.tolist()\n",
    "train_y = train_df.label\n",
    "dev_x = dev_df.text.tolist()\n",
    "dev_y = dev_df.label\n",
    "test_x = test_df.text.tolist()\n",
    "test_y = test_df.label\n",
    "\n",
    "max_len = 49\n",
    "# tokenizer = create_tokenizer(train_x)\n",
    "with open(\"/content/drive/MyDrive/Sentiment Analysis/tokenizer/49in_SST.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_index = tokenizer.word_index\n",
    "train_x = encode_text(tokenizer, train_x, max_len)\n",
    "dev_x = encode_text(tokenizer, dev_x, max_len)\n",
    "test_x = encode_text(tokenizer, test_x, max_len)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train_y).reshape(-1, 1)\n",
    "dev_y = le.transform(dev_y).reshape(-1, 1)\n",
    "test_y = le.transform(test_y).reshape(-1, 1)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtoxFTHhne5v"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b8g1hAT9ne5w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552494934,
     "user_tz": -480,
     "elapsed": 20241,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "def get_embeddings_layer(name, max_len, trainable):\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=len(word_index)+1,\n",
    "        output_dim=50,\n",
    "        input_length=max_len,\n",
    "        # weights=[embeddings_matrix],\n",
    "        trainable=trainable,\n",
    "        name=name,\n",
    "    )\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def get_LSTM(max_len):\n",
    "    embeddings_layer = get_embeddings_layer(\n",
    "       \"embeddings_layer\", max_len, trainable=True\n",
    "    )\n",
    "\n",
    "    # dynamic channel\n",
    "    in_layer = Input(shape=(max_len,), dtype=\"int32\", name=\"input\")\n",
    "    layer = embeddings_layer(in_layer)\n",
    "    \n",
    "    layer = Bidirectional(LSTM(64,return_sequences=True))(layer)\n",
    "    layer = Bidirectional(LSTM(64))(layer)\n",
    "    layer = Dropout(0.1)(layer)\n",
    "    layer = Dense(20, activation=\"relu\", name=\"FC1\")(layer)\n",
    "    # layer = Dropout(0.1)(layer)\n",
    "\n",
    "    o = Dense(1, activation=\"sigmoid\", name=\"output\",)(layer)\n",
    "\n",
    "    model = Model(inputs=in_layer, outputs=o)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n19GzqOvne5z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552494935,
     "user_tz": -480,
     "elapsed": 19736,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"val_acc\") > 0.8:\n",
    "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "beststop = myCallback()\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0.0001)\n",
    "checkpointer = ModelCheckpoint(filepath=\"./weights.hdf5\", verbose=1)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2_NteEQzne50",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618552494935,
     "user_tz": -480,
     "elapsed": 19319,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "def TrainModel(num):\n",
    "    while num > 0:\n",
    "        model = get_LSTM(max_len)\n",
    "        # model.summary()\n",
    "        history = model.fit(\n",
    "            x=train_x,\n",
    "            y=train_y,\n",
    "            batch_size=50,\n",
    "            epochs=20,\n",
    "            validation_data=(test_x, test_y),\n",
    "            callbacks=[earlystop],\n",
    "        )\n",
    "        if history.history[\"val_acc\"][-1] > 0.8:\n",
    "            save_name = (\n",
    "                \"/content/drive/MyDrive/Sentiment Analysis/Model/BiLSTM_SST/\"\n",
    "                + str(history.history[\"val_loss\"][-1])[2:6]\n",
    "                + \"_\"\n",
    "                + str(history.history[\"val_acc\"][-1])[2:6]\n",
    "                + \".hdf5\"\n",
    "            )\n",
    "            num -= 1\n",
    "            model.save(save_name)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgZP84VHne53",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618553126082,
     "user_tz": -480,
     "elapsed": 649572,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "049bc00a-7f83-49c7-b984-c46553332683"
   },
   "source": [
    "TrainModel(10)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "139/139 [==============================] - 25s 34ms/step - loss: 0.6750 - acc: 0.5228 - val_loss: 0.4762 - val_acc: 0.7820\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.3201 - acc: 0.8676 - val_loss: 0.4677 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1359 - acc: 0.9563 - val_loss: 0.5376 - val_acc: 0.7908\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6698 - acc: 0.5689 - val_loss: 0.4916 - val_acc: 0.7732\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2920 - acc: 0.8869 - val_loss: 0.4532 - val_acc: 0.7886\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1199 - acc: 0.9604 - val_loss: 0.6168 - val_acc: 0.7902\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6637 - acc: 0.5669 - val_loss: 0.4560 - val_acc: 0.7831\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2800 - acc: 0.8891 - val_loss: 0.4458 - val_acc: 0.8116\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1157 - acc: 0.9623 - val_loss: 0.5668 - val_acc: 0.8023\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6692 - acc: 0.5507 - val_loss: 0.4715 - val_acc: 0.7743\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.3014 - acc: 0.8808 - val_loss: 0.4508 - val_acc: 0.8034\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1292 - acc: 0.9598 - val_loss: 0.5923 - val_acc: 0.7996\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6669 - acc: 0.5725 - val_loss: 0.4683 - val_acc: 0.7858\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2906 - acc: 0.8828 - val_loss: 0.4442 - val_acc: 0.8012\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1014 - acc: 0.9698 - val_loss: 0.6034 - val_acc: 0.7968\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 34ms/step - loss: 0.6682 - acc: 0.5751 - val_loss: 0.4832 - val_acc: 0.7738\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2783 - acc: 0.8908 - val_loss: 0.4779 - val_acc: 0.7985\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1023 - acc: 0.9662 - val_loss: 0.5415 - val_acc: 0.8023\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6627 - acc: 0.5814 - val_loss: 0.4562 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2878 - acc: 0.8879 - val_loss: 0.4604 - val_acc: 0.7919\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6650 - acc: 0.5599 - val_loss: 0.4513 - val_acc: 0.7952\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2761 - acc: 0.8908 - val_loss: 0.4509 - val_acc: 0.8051\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1101 - acc: 0.9611 - val_loss: 0.5681 - val_acc: 0.8012\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6630 - acc: 0.5625 - val_loss: 0.4638 - val_acc: 0.7831\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2782 - acc: 0.8900 - val_loss: 0.4364 - val_acc: 0.8029\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1119 - acc: 0.9635 - val_loss: 0.5348 - val_acc: 0.8007\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6696 - acc: 0.5580 - val_loss: 0.4829 - val_acc: 0.7694\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.3001 - acc: 0.8847 - val_loss: 0.4286 - val_acc: 0.8166\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1195 - acc: 0.9585 - val_loss: 0.5290 - val_acc: 0.8051\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6709 - acc: 0.5605 - val_loss: 0.4662 - val_acc: 0.7836\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.3002 - acc: 0.8807 - val_loss: 0.4442 - val_acc: 0.8040\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1267 - acc: 0.9596 - val_loss: 0.6374 - val_acc: 0.7875\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6609 - acc: 0.5782 - val_loss: 0.4767 - val_acc: 0.7748\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.3065 - acc: 0.8805 - val_loss: 0.4521 - val_acc: 0.8040\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1195 - acc: 0.9584 - val_loss: 0.5364 - val_acc: 0.7902\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 31ms/step - loss: 0.6707 - acc: 0.5581 - val_loss: 0.4660 - val_acc: 0.7891\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2987 - acc: 0.8815 - val_loss: 0.4511 - val_acc: 0.8182\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1198 - acc: 0.9601 - val_loss: 0.5347 - val_acc: 0.7996\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6750 - acc: 0.5376 - val_loss: 0.4660 - val_acc: 0.7842\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2853 - acc: 0.8860 - val_loss: 0.4513 - val_acc: 0.8072\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 25ms/step - loss: 0.1205 - acc: 0.9619 - val_loss: 0.5358 - val_acc: 0.7897\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6545 - acc: 0.5907 - val_loss: 0.4466 - val_acc: 0.8089\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2682 - acc: 0.8969 - val_loss: 0.4701 - val_acc: 0.7957\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6600 - acc: 0.5654 - val_loss: 0.4539 - val_acc: 0.7897\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 4s 25ms/step - loss: 0.2760 - acc: 0.8883 - val_loss: 0.4498 - val_acc: 0.8023\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1138 - acc: 0.9612 - val_loss: 0.5777 - val_acc: 0.7902\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6641 - acc: 0.5604 - val_loss: 0.4766 - val_acc: 0.7858\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2999 - acc: 0.8802 - val_loss: 0.4472 - val_acc: 0.7990\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1339 - acc: 0.9559 - val_loss: 0.5914 - val_acc: 0.7996\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6575 - acc: 0.5730 - val_loss: 0.4794 - val_acc: 0.7853\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2767 - acc: 0.8957 - val_loss: 0.4832 - val_acc: 0.7930\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 32ms/step - loss: 0.6828 - acc: 0.5276 - val_loss: 0.5102 - val_acc: 0.7523\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 25ms/step - loss: 0.3473 - acc: 0.8519 - val_loss: 0.4279 - val_acc: 0.8007\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1216 - acc: 0.9595 - val_loss: 0.5929 - val_acc: 0.7820\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 34ms/step - loss: 0.6652 - acc: 0.5667 - val_loss: 0.4574 - val_acc: 0.7919\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2927 - acc: 0.8830 - val_loss: 0.4832 - val_acc: 0.7974\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6620 - acc: 0.5694 - val_loss: 0.4541 - val_acc: 0.7968\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2897 - acc: 0.8820 - val_loss: 0.4639 - val_acc: 0.7880\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 32ms/step - loss: 0.6623 - acc: 0.5637 - val_loss: 0.4620 - val_acc: 0.7908\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2817 - acc: 0.8876 - val_loss: 0.4520 - val_acc: 0.8062\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1175 - acc: 0.9593 - val_loss: 0.6043 - val_acc: 0.8034\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6761 - acc: 0.5299 - val_loss: 0.4615 - val_acc: 0.7820\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.3221 - acc: 0.8685 - val_loss: 0.4284 - val_acc: 0.8105\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1267 - acc: 0.9567 - val_loss: 0.5377 - val_acc: 0.7836\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6637 - acc: 0.5789 - val_loss: 0.4726 - val_acc: 0.7748\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2883 - acc: 0.8835 - val_loss: 0.4325 - val_acc: 0.7996\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1246 - acc: 0.9580 - val_loss: 0.5398 - val_acc: 0.7957\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6674 - acc: 0.5663 - val_loss: 0.4428 - val_acc: 0.7974\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2849 - acc: 0.8858 - val_loss: 0.4550 - val_acc: 0.7941\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6692 - acc: 0.5506 - val_loss: 0.4558 - val_acc: 0.7913\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2882 - acc: 0.8843 - val_loss: 0.4379 - val_acc: 0.8177\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1114 - acc: 0.9618 - val_loss: 0.5914 - val_acc: 0.7946\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6682 - acc: 0.5464 - val_loss: 0.4551 - val_acc: 0.7963\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2955 - acc: 0.8748 - val_loss: 0.4331 - val_acc: 0.8116\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.0966 - acc: 0.9659 - val_loss: 0.6501 - val_acc: 0.7836\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6718 - acc: 0.5707 - val_loss: 0.4967 - val_acc: 0.7847\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.3156 - acc: 0.8786 - val_loss: 0.4498 - val_acc: 0.8056\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1146 - acc: 0.9606 - val_loss: 0.5862 - val_acc: 0.8001\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6608 - acc: 0.5708 - val_loss: 0.4634 - val_acc: 0.7842\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2791 - acc: 0.8905 - val_loss: 0.4802 - val_acc: 0.8089\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 34ms/step - loss: 0.6647 - acc: 0.5590 - val_loss: 0.4640 - val_acc: 0.7880\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2837 - acc: 0.8897 - val_loss: 0.4613 - val_acc: 0.8083\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1077 - acc: 0.9662 - val_loss: 0.5835 - val_acc: 0.7979\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 35ms/step - loss: 0.6618 - acc: 0.5700 - val_loss: 0.4922 - val_acc: 0.7573\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 25ms/step - loss: 0.2821 - acc: 0.8908 - val_loss: 0.4462 - val_acc: 0.8062\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1126 - acc: 0.9623 - val_loss: 0.6128 - val_acc: 0.7858\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 32ms/step - loss: 0.6564 - acc: 0.5910 - val_loss: 0.5006 - val_acc: 0.7507\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2977 - acc: 0.8933 - val_loss: 0.4760 - val_acc: 0.8040\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1159 - acc: 0.9620 - val_loss: 0.6053 - val_acc: 0.7968\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6623 - acc: 0.5688 - val_loss: 0.4448 - val_acc: 0.7875\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2752 - acc: 0.8863 - val_loss: 0.4509 - val_acc: 0.8116\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 10s 37ms/step - loss: 0.6587 - acc: 0.5808 - val_loss: 0.5100 - val_acc: 0.7490\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2825 - acc: 0.8815 - val_loss: 0.4637 - val_acc: 0.7990\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1068 - acc: 0.9624 - val_loss: 0.6265 - val_acc: 0.7825\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 32ms/step - loss: 0.6646 - acc: 0.5642 - val_loss: 0.4701 - val_acc: 0.7803\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2840 - acc: 0.8886 - val_loss: 0.5051 - val_acc: 0.7913\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6584 - acc: 0.5809 - val_loss: 0.4821 - val_acc: 0.7688\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.2787 - acc: 0.8955 - val_loss: 0.4779 - val_acc: 0.8034\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1228 - acc: 0.9559 - val_loss: 0.5472 - val_acc: 0.7935\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 36ms/step - loss: 0.6680 - acc: 0.5464 - val_loss: 0.4564 - val_acc: 0.7858\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.2934 - acc: 0.8797 - val_loss: 0.4413 - val_acc: 0.8078\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 24ms/step - loss: 0.1157 - acc: 0.9631 - val_loss: 0.5115 - val_acc: 0.7974\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 9s 33ms/step - loss: 0.6727 - acc: 0.5577 - val_loss: 0.4512 - val_acc: 0.7919\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.3040 - acc: 0.8809 - val_loss: 0.4440 - val_acc: 0.8018\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.1213 - acc: 0.9564 - val_loss: 0.5220 - val_acc: 0.8007\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DrRb6_yVne6K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618044265806,
     "user_tz": -480,
     "elapsed": 1730,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "41b52c8b-f705-4e4b-afce-de86b07dda75"
   },
   "source": [
    "# del model\n",
    "model = get_LSTM(max_len)\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 49)]              0         \n",
      "_________________________________________________________________\n",
      "embeddings_layer (Embedding) (None, 49, 50)            691800    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 49, 128)           58880     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 852,097\n",
      "Trainable params: 852,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zdN3TkmwnkoU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1618044307223,
     "user_tz": -480,
     "elapsed": 24140,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "b9afbffd-12fd-47f3-e3e6-fe45009ea3d6"
   },
   "source": [
    "history = model.fit(\n",
    "            x=train_x,\n",
    "            y=train_y,\n",
    "            batch_size=50,\n",
    "            epochs=20,\n",
    "            validation_data=(test_x, test_y),\n",
    "            # callbacks=[earlystop],\n",
    "        )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "139/139 [==============================] - 10s 33ms/step - loss: 0.6604 - acc: 0.5831 - val_loss: 0.4799 - val_acc: 0.7666\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 25ms/step - loss: 0.2885 - acc: 0.8873 - val_loss: 0.4751 - val_acc: 0.8051\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 4s 27ms/step - loss: 0.1028 - acc: 0.9648 - val_loss: 0.5765 - val_acc: 0.7941\n",
      "Epoch 4/20\n",
      "139/139 [==============================] - 3s 25ms/step - loss: 0.0550 - acc: 0.9841 - val_loss: 0.7984 - val_acc: 0.7897\n",
      "Epoch 5/20\n",
      "130/139 [===========================>..] - ETA: 0s - loss: 0.0251 - acc: 0.9922"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-ee3303c67b4b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m             \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m             \u001B[0;31m# callbacks=[earlystop],\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1098\u001B[0m                 _r=1):\n\u001B[1;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    853\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 855\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    856\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    857\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 2943\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   2944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2945\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1917\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1918\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1919\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1921\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    558\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 560\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    561\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    562\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zPnpaWf_ne6K"
   },
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 保存模型\n",
    "# model.save(\"10in_32unit_temp_res.h5\")\n",
    "# del model  # deletes the existing model\n",
    "# 导入已经训练好的模型\n",
    "# model = load_model(\"my_model.h5\")\n",
    "## 保存训练好的Tokenizer，和导入\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"/content/drive/MyDrive/Sentiment Analysis/tokenizer/49in_SST.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "dCKauqOfne6L",
    "executionInfo": {
     "status": "error",
     "timestamp": 1618040790731,
     "user_tz": -480,
     "elapsed": 799,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "0dfa94e3-8a59-4c23-c3f7-8d9b7a22d876"
   },
   "source": [],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-107-986df98acfc1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_x\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1387\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1388\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1389\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1390\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1391\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    860\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    861\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 862\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    863\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    864\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2939\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[0;32m-> 2941\u001B[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[1;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3356\u001B[0m               call_context_key in self._function_cache.missed):\n\u001B[1;32m   3357\u001B[0m             return self._define_function_with_shape_relaxation(\n\u001B[0;32m-> 3358\u001B[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0m\u001B[1;32m   3359\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_define_function_with_shape_relaxation\u001B[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001B[0m\n\u001B[1;32m   3278\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3279\u001B[0m     graph_function = self._create_graph_function(\n\u001B[0;32m-> 3280\u001B[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001B[0m\u001B[1;32m   3281\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marg_relaxed\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mrank_only_cache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3282\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3204\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3205\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3206\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3207\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3208\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    632\u001B[0m             \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 977\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    978\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_15 expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 49) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 49) dtype=int32>]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkkdvFiAne6M"
   },
   "source": [
    "### google"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dk2R4i81ne6M"
   },
   "source": [
    "def load_google():\n",
    "    Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n",
    "    )\n",
    "\n",
    "    vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n",
    "\n",
    "    # word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "    embeddings_index = {}  # 初始化`[word : vector]`字典\n",
    "\n",
    "    for i in range(len(vocab_list)):\n",
    "        # print(i)\n",
    "        word = vocab_list[i]  # 每个词语\n",
    "        # word_index[word] = i + 1 # 词语：序号\n",
    "        embeddings_index[word] = Word2VecModel.wv[word]  # 词语：词向量\n",
    "        # embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def load_fasttext_embeddings():\n",
    "    glove_dir = r\"E:\\CS\\MLT\\glove.6B\"\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(glove_dir, \"glove.6B.50d.txt\"), encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def create_embeddings_matrix(embeddings_index, vocabulary, embedding_dim=100):\n",
    "    embeddings_matrix = np.random.rand(len(vocabulary) + 1, embedding_dim)\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embeddings_matrix[i] = embedding_vector\n",
    "    print(\"Matrix shape: {}\".format(embeddings_matrix.shape))\n",
    "    return embeddings_matrix\n",
    "\n",
    "\n",
    "embeddings_index = load_google()\n",
    "embeddings_matrix = create_embeddings_matrix(embeddings_index, word_index, 300)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ANOlCJ1tne6P"
   },
   "source": [
    "import gensim\n",
    "\n",
    "Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")\n",
    "\n",
    "vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n",
    "\n",
    "word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "word_vector = {}  # 初始化`[word : vector]`字典\n",
    "\n",
    "for i in range(len(vocab_list)):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    #     word_index[word] = i + 1 # 词语：序号\n",
    "    #     word_vector[word] = Word2VecModel.wv[word] # 词语：词向量\n",
    "    embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
