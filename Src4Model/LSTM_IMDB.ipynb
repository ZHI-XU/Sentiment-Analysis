{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"LSTM_IMDB.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gwcXt_Kcne5N"},"source":["# LSTM_SST\n"]},{"cell_type":"code","metadata":{"id":"tq9imcf0ne5o","executionInfo":{"status":"ok","timestamp":1618981103712,"user_tz":-480,"elapsed":3865,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["import os\n","import numpy as np\n","import string\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","import pickle\n","import pandas as pd\n","\n","\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.activations import relu\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import (\n","    Input,\n","    Dense,\n","    Embedding,\n","    Flatten,\n","    Conv1D,\n","    MaxPooling1D,\n","    Add,\n","    Lambda,\n","    Dropout,\n","    concatenate,\n","    LSTM,\n",")\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.backend import l2_normalize\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","from sklearn.metrics import classification_report\n","from nltk.corpus import stopwords\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from IPython.display import SVG"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_GjM47tne5r","executionInfo":{"status":"ok","timestamp":1618981103713,"user_tz":-480,"elapsed":3468,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["def ModiData(obj_df):\n","    obj_df = obj_df[obj_df[\"label\"] != 2]\n","    # obj_df[\"label\"] = obj_df[\"label\"].astype(string)\n","    obj_df.label = obj_df.label.replace(0, \"neg\")\n","    obj_df.label = obj_df.label.replace(1, \"neg\")\n","    obj_df.label = obj_df.label.replace(3, \"pos\")\n","    obj_df.label = obj_df.label.replace(4, \"pos\")\n","    obj_df = obj_df.fillna(0)\n","    # obj_df[\"label\"] = obj_df[\"label\"].astype(int)\n","    return obj_df\n","\n","\n","def clean_line(line):\n","    # split into tokens by white space\n","    tokens = line.split()\n","    # remove punctuation from each token\n","    table = str.maketrans(\"\", \"\", string.punctuation)\n","    tokens = [w.translate(table) for w in tokens]\n","    # remove remaining tokens that are not alphabetic\n","    tokens = [word for word in tokens if word.isalpha()]\n","    # filter out stop words\n","    stop_words = set(stopwords.words(\"english\"))\n","    tokens = [w for w in tokens if not w in stop_words]\n","    # filter out short tokens\n","    tokens = [word for word in tokens if len(word) > 1]\n","    return tokens\n","\n","\n","def create_tokenizer(lines):\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(lines)\n","    return tokenizer\n","\n","\n","def encode_text(tokenizer, lines, length):\n","    # integer encode\n","    encoded = tokenizer.texts_to_sequences(lines)\n","    # pad encoded sequences\n","    padded = pad_sequences(encoded, maxlen=length, padding=\"post\")\n","    return padded"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpoYt1QtFVr1","executionInfo":{"status":"ok","timestamp":1618981107358,"user_tz":-480,"elapsed":4049,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["train_df = pd.read_csv(\n","    \"/content/drive/MyDrive/Sentiment Analysis/IMDB/train.csv\", \n",")\n","\n","test_df = pd.read_csv(\n","    \"/content/drive/MyDrive/Sentiment Analysis/IMDB/test.csv\", \n",")\n","\n","train_df = train_df.sample(frac=1).reset_index(drop=True)\n","test_df = test_df.sample(frac=1).reset_index(drop=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hoxxs-jane5t","executionInfo":{"status":"ok","timestamp":1618981115699,"user_tz":-480,"elapsed":11394,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["# train_df = ModiData(train_df)\n","# # dev_df = ModiData(dev_df)\n","# test_df = ModiData(test_df)\n","\n","train_x = train_df.text.tolist()\n","train_y = train_df.label\n","# dev_x = dev_df.text.tolist()\n","# dev_y = dev_df.label\n","test_x = test_df.text.tolist()\n","test_y = test_df.label\n","\n","max_len = 200\n","# tokenizer = create_tokenizer(train_x)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/tokenizer/200in_IMDB.pickle\", \"rb\") as handle:\n","    tokenizer = pickle.load(handle)\n","# calculate vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1\n","word_index = tokenizer.word_index\n","train_x = encode_text(tokenizer, train_x, max_len)\n","# dev_x = encode_text(tokenizer, dev_x, max_len)\n","test_x = encode_text(tokenizer, test_x, max_len)\n","\n","le = LabelEncoder()\n","train_y = le.fit_transform(train_y).reshape(-1, 1)\n","# dev_y = le.transform(dev_y).reshape(-1, 1)\n","test_y = le.transform(test_y).reshape(-1, 1)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JtoxFTHhne5v"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"b8g1hAT9ne5w","executionInfo":{"status":"ok","timestamp":1618982005239,"user_tz":-480,"elapsed":1200,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["def get_embeddings_layer(name, max_len, trainable):\n","    embedding_layer = Embedding(\n","        input_dim=len(word_index)+1,\n","        output_dim=50,\n","        input_length=max_len,\n","        # weights=[embeddings_matrix],\n","        trainable=trainable,\n","        name=name,\n","    )\n","    return embedding_layer\n","\n","\n","def get_LSTM(max_len):\n","    embeddings_layer = get_embeddings_layer(\n","       \"embeddings_layer\", max_len, trainable=True\n","    )\n","\n","    # dynamic channel\n","    in_layer = Input(shape=(max_len,), dtype=\"int32\", name=\"input\")\n","    layer = embeddings_layer(in_layer)\n","    \n","    layer = LSTM(256,return_sequences=True)(layer)\n","    layer = LSTM(256)(layer)\n","    layer = Dropout(0.5)(layer)\n","    layer = Dense(64, activation=\"relu\", name=\"FC1\")(layer)\n","    # layer = Dropout(0.5)(layer)\n","\n","    o = Dense(1, activation=\"sigmoid\", name=\"output\",)(layer)\n","\n","    model = Model(inputs=in_layer, outputs=o)\n","    model.compile(\n","        loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"],\n","    )\n","\n","    return model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"n19GzqOvne5z","executionInfo":{"status":"ok","timestamp":1618982424588,"user_tz":-480,"elapsed":1031,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get(\"val_loss\") < 0.36:\n","            print(\"\\nReached 0.34 loss\")\n","            self.model.stop_training = True\n","\n","\n","beststop = myCallback()\n","earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0.01)\n","checkpointer = ModelCheckpoint(filepath=\"./weights.hdf5\", verbose=1)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_NteEQzne50","executionInfo":{"status":"ok","timestamp":1618982425053,"user_tz":-480,"elapsed":1158,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}}},"source":["def TrainModel(num):\n","    while num > 0:\n","        model = get_LSTM(max_len)\n","        # model.summary()\n","        history = model.fit(\n","            x=train_x,\n","            y=train_y,\n","            batch_size=400,\n","            epochs=8,\n","            validation_data=(test_x, test_y),\n","            callbacks=[beststop,],\n","        )\n","        if history.history[\"val_acc\"][-1] >= 0.86:\n","            save_name = (\n","                \"/content/drive/MyDrive/Sentiment Analysis/Model/LSTM_IMDB/\"\n","                + str(history.history[\"val_loss\"][-1])[2:6]\n","                + \"_\"\n","                + str(history.history[\"val_acc\"][-1])[2:6]\n","                + \".hdf5\"\n","            )\n","            num -= 1\n","            model.save(save_name)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"XgZP84VHne53","executionInfo":{"status":"ok","timestamp":1618990867333,"user_tz":-480,"elapsed":8441487,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}},"outputId":"3503c38c-3173-4213-c19e-f00566bd4992"},"source":["TrainModel(10)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/8\n","63/63 [==============================] - 12s 154ms/step - loss: 0.6989 - acc: 0.5046 - val_loss: 0.6894 - val_acc: 0.5356\n","Epoch 2/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.6889 - acc: 0.5316 - val_loss: 0.6845 - val_acc: 0.5473\n","Epoch 3/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.6790 - acc: 0.5496 - val_loss: 0.6787 - val_acc: 0.5243\n","Epoch 4/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6629 - acc: 0.5945 - val_loss: 0.6851 - val_acc: 0.5700\n","Epoch 5/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6465 - acc: 0.5946 - val_loss: 0.4376 - val_acc: 0.8296\n","Epoch 6/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.2977 - acc: 0.8861 - val_loss: 0.3480 - val_acc: 0.8561\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 155ms/step - loss: 0.6949 - acc: 0.5079 - val_loss: 0.6881 - val_acc: 0.5921\n","Epoch 2/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.6933 - acc: 0.5505 - val_loss: 0.6857 - val_acc: 0.5525\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6639 - acc: 0.6145 - val_loss: 0.6548 - val_acc: 0.5973\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5619 - acc: 0.6995 - val_loss: 0.4354 - val_acc: 0.8266\n","Epoch 5/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.2998 - acc: 0.8941 - val_loss: 0.3630 - val_acc: 0.8505\n","Epoch 6/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.1701 - acc: 0.9468 - val_loss: 0.4054 - val_acc: 0.8564\n","Epoch 7/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.0929 - acc: 0.9751 - val_loss: 0.4230 - val_acc: 0.8537\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.0513 - acc: 0.9876 - val_loss: 0.4376 - val_acc: 0.8376\n","Epoch 1/8\n","63/63 [==============================] - 12s 152ms/step - loss: 0.6922 - acc: 0.5156 - val_loss: 0.6930 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 140ms/step - loss: 0.7248 - acc: 0.5588 - val_loss: 0.6866 - val_acc: 0.5724\n","Epoch 3/8\n","63/63 [==============================] - 9s 140ms/step - loss: 0.6476 - acc: 0.6355 - val_loss: 0.4942 - val_acc: 0.8007\n","Epoch 4/8\n","63/63 [==============================] - 9s 140ms/step - loss: 0.5363 - acc: 0.7273 - val_loss: 0.4989 - val_acc: 0.7951\n","Epoch 5/8\n","63/63 [==============================] - 9s 139ms/step - loss: 0.4866 - acc: 0.7834 - val_loss: 0.4600 - val_acc: 0.8101\n","Epoch 6/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.4069 - acc: 0.8409 - val_loss: 0.4597 - val_acc: 0.8158\n","Epoch 7/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.3283 - acc: 0.8894 - val_loss: 0.4964 - val_acc: 0.8133\n","Epoch 8/8\n","63/63 [==============================] - 9s 140ms/step - loss: 0.3667 - acc: 0.8688 - val_loss: 0.4780 - val_acc: 0.8210\n","Epoch 1/8\n","63/63 [==============================] - 13s 155ms/step - loss: 0.6943 - acc: 0.5173 - val_loss: 0.7030 - val_acc: 0.4995\n","Epoch 2/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.7030 - acc: 0.5040 - val_loss: 0.6878 - val_acc: 0.5516\n","Epoch 3/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.6722 - acc: 0.5886 - val_loss: 0.6345 - val_acc: 0.6325\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5699 - acc: 0.7128 - val_loss: 0.6739 - val_acc: 0.5795\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6687 - acc: 0.5798 - val_loss: 0.6668 - val_acc: 0.6197\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6492 - acc: 0.6108 - val_loss: 0.6985 - val_acc: 0.5403\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6455 - acc: 0.6337 - val_loss: 0.6291 - val_acc: 0.6309\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6243 - acc: 0.6816 - val_loss: 0.5522 - val_acc: 0.7420\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6934 - acc: 0.5122 - val_loss: 0.6924 - val_acc: 0.5001\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6848 - acc: 0.5644 - val_loss: 0.6571 - val_acc: 0.6085\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5062 - acc: 0.7389 - val_loss: 0.3470 - val_acc: 0.8652\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6957 - acc: 0.5081 - val_loss: 0.6964 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6882 - acc: 0.5441 - val_loss: 0.5968 - val_acc: 0.7349\n","Epoch 3/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.5185 - acc: 0.7868 - val_loss: 0.5205 - val_acc: 0.7851\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.4542 - acc: 0.8131 - val_loss: 0.5478 - val_acc: 0.7998\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5341 - acc: 0.7788 - val_loss: 0.5661 - val_acc: 0.7094\n","Epoch 6/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.4875 - acc: 0.7808 - val_loss: 0.5856 - val_acc: 0.7850\n","Epoch 7/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.4674 - acc: 0.8278 - val_loss: 0.5886 - val_acc: 0.6987\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5479 - acc: 0.7391 - val_loss: 0.6225 - val_acc: 0.6288\n","Epoch 1/8\n","63/63 [==============================] - 12s 155ms/step - loss: 0.6971 - acc: 0.5093 - val_loss: 0.6628 - val_acc: 0.6060\n","Epoch 2/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6942 - acc: 0.5603 - val_loss: 0.6906 - val_acc: 0.5183\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6806 - acc: 0.5563 - val_loss: 0.6208 - val_acc: 0.6313\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5551 - acc: 0.7027 - val_loss: 0.4241 - val_acc: 0.8388\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3277 - acc: 0.8844 - val_loss: 0.4468 - val_acc: 0.8381\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.2521 - acc: 0.9182 - val_loss: 0.4655 - val_acc: 0.8318\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.2517 - acc: 0.9201 - val_loss: 0.5300 - val_acc: 0.7916\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.2876 - acc: 0.9096 - val_loss: 0.5007 - val_acc: 0.8090\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6932 - acc: 0.5134 - val_loss: 0.6939 - val_acc: 0.5004\n","Epoch 2/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6888 - acc: 0.5156 - val_loss: 0.6700 - val_acc: 0.5539\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6626 - acc: 0.5915 - val_loss: 0.6555 - val_acc: 0.5870\n","Epoch 4/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.5829 - acc: 0.6763 - val_loss: 0.5109 - val_acc: 0.7684\n","Epoch 5/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.3754 - acc: 0.8479 - val_loss: 0.4584 - val_acc: 0.8163\n","Epoch 6/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.3376 - acc: 0.8805 - val_loss: 0.4314 - val_acc: 0.8258\n","Epoch 7/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.2778 - acc: 0.9149 - val_loss: 0.4626 - val_acc: 0.8218\n","Epoch 8/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.2266 - acc: 0.9250 - val_loss: 0.4477 - val_acc: 0.8423\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6962 - acc: 0.5155 - val_loss: 1.1971 - val_acc: 0.5001\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.7318 - acc: 0.5353 - val_loss: 0.6733 - val_acc: 0.5708\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6780 - acc: 0.5572 - val_loss: 0.6717 - val_acc: 0.5680\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6719 - acc: 0.5588 - val_loss: 0.6749 - val_acc: 0.5334\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6819 - acc: 0.5166 - val_loss: 0.6937 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6954 - acc: 0.4942 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6937 - acc: 0.5054 - val_loss: 0.6939 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6935 - acc: 0.5050 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 159ms/step - loss: 0.6963 - acc: 0.5097 - val_loss: 0.6378 - val_acc: 0.6605\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6906 - acc: 0.5508 - val_loss: 0.6768 - val_acc: 0.5663\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6117 - acc: 0.6625 - val_loss: 0.6297 - val_acc: 0.6372\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5390 - acc: 0.7371 - val_loss: 0.5501 - val_acc: 0.7410\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4825 - acc: 0.7877 - val_loss: 0.4902 - val_acc: 0.8096\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4043 - acc: 0.8512 - val_loss: 0.6587 - val_acc: 0.5976\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6162 - acc: 0.6390 - val_loss: 0.5329 - val_acc: 0.7370\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4409 - acc: 0.8122 - val_loss: 0.4868 - val_acc: 0.8055\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6932 - acc: 0.5078 - val_loss: 0.6986 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6919 - acc: 0.5260 - val_loss: 0.6634 - val_acc: 0.5974\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6467 - acc: 0.6168 - val_loss: 0.9339 - val_acc: 0.6130\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.7401 - acc: 0.5243 - val_loss: 0.6905 - val_acc: 0.5014\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6903 - acc: 0.5283 - val_loss: 0.6672 - val_acc: 0.5898\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6377 - acc: 0.6571 - val_loss: 0.5992 - val_acc: 0.6886\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6344 - acc: 0.6276 - val_loss: 0.6913 - val_acc: 0.5138\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6829 - acc: 0.5495 - val_loss: 0.6652 - val_acc: 0.5780\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6929 - acc: 0.5007 - val_loss: 0.6854 - val_acc: 0.5521\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6635 - acc: 0.5845 - val_loss: 0.6125 - val_acc: 0.6562\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5798 - acc: 0.7065 - val_loss: 0.4830 - val_acc: 0.8019\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4029 - acc: 0.8475 - val_loss: 0.5538 - val_acc: 0.7673\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3927 - acc: 0.8444 - val_loss: 0.4880 - val_acc: 0.8026\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4034 - acc: 0.8524 - val_loss: 0.5663 - val_acc: 0.7480\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4473 - acc: 0.8126 - val_loss: 0.5508 - val_acc: 0.7747\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5244 - acc: 0.7530 - val_loss: 0.6094 - val_acc: 0.7974\n","Epoch 1/8\n","63/63 [==============================] - 12s 154ms/step - loss: 0.6940 - acc: 0.5127 - val_loss: 0.6959 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6888 - acc: 0.5469 - val_loss: 0.6850 - val_acc: 0.6506\n","Epoch 3/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6829 - acc: 0.5610 - val_loss: 0.6892 - val_acc: 0.5121\n","Epoch 4/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6811 - acc: 0.5548 - val_loss: 0.6274 - val_acc: 0.6090\n","Epoch 5/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.5299 - acc: 0.7413 - val_loss: 0.5165 - val_acc: 0.7752\n","Epoch 6/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.3938 - acc: 0.8579 - val_loss: 0.4768 - val_acc: 0.8187\n","Epoch 7/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.3271 - acc: 0.8793 - val_loss: 0.4648 - val_acc: 0.8066\n","Epoch 8/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.2399 - acc: 0.9175 - val_loss: 0.3901 - val_acc: 0.8492\n","Epoch 1/8\n","63/63 [==============================] - 13s 157ms/step - loss: 0.6980 - acc: 0.5069 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6949 - acc: 0.5107 - val_loss: 0.6832 - val_acc: 0.5280\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6814 - acc: 0.5902 - val_loss: 0.6898 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6798 - acc: 0.5745 - val_loss: 0.6715 - val_acc: 0.5949\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5827 - acc: 0.6877 - val_loss: 0.5499 - val_acc: 0.7494\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6389 - acc: 0.7284 - val_loss: 0.5785 - val_acc: 0.6754\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4516 - acc: 0.8066 - val_loss: 0.3905 - val_acc: 0.8442\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.2750 - acc: 0.9019 - val_loss: 0.3817 - val_acc: 0.8474\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6943 - acc: 0.5132 - val_loss: 0.6895 - val_acc: 0.5618\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.7059 - acc: 0.5664 - val_loss: 0.6737 - val_acc: 0.5809\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6707 - acc: 0.6026 - val_loss: 0.5540 - val_acc: 0.7283\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5789 - acc: 0.6990 - val_loss: 0.6393 - val_acc: 0.6045\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5122 - acc: 0.7411 - val_loss: 0.5940 - val_acc: 0.6764\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5665 - acc: 0.7076 - val_loss: 0.5948 - val_acc: 0.7050\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5487 - acc: 0.7384 - val_loss: 0.6082 - val_acc: 0.6428\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5377 - acc: 0.7339 - val_loss: 0.5476 - val_acc: 0.7342\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6928 - acc: 0.5162 - val_loss: 0.6591 - val_acc: 0.6022\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4668 - acc: 0.7919 - val_loss: 0.3429 - val_acc: 0.8604\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6948 - acc: 0.5134 - val_loss: 0.6840 - val_acc: 0.5670\n","Epoch 2/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.6862 - acc: 0.5426 - val_loss: 0.6751 - val_acc: 0.5518\n","Epoch 3/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6327 - acc: 0.6185 - val_loss: 0.6178 - val_acc: 0.7860\n","Epoch 4/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.4865 - acc: 0.7951 - val_loss: 0.6215 - val_acc: 0.6266\n","Epoch 5/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.4828 - acc: 0.8038 - val_loss: 0.8372 - val_acc: 0.5934\n","Epoch 6/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.5689 - acc: 0.6912 - val_loss: 0.5833 - val_acc: 0.7052\n","Epoch 7/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.5194 - acc: 0.7551 - val_loss: 0.5666 - val_acc: 0.7204\n","Epoch 8/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.4992 - acc: 0.7854 - val_loss: 0.5893 - val_acc: 0.7153\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6928 - acc: 0.5142 - val_loss: 0.6858 - val_acc: 0.5809\n","Epoch 2/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6483 - acc: 0.5958 - val_loss: 0.8034 - val_acc: 0.5000\n","Epoch 3/8\n","63/63 [==============================] - 9s 140ms/step - loss: 0.7010 - acc: 0.5286 - val_loss: 0.6722 - val_acc: 0.5754\n","Epoch 4/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6411 - acc: 0.6506 - val_loss: 0.4829 - val_acc: 0.8260\n","Epoch 5/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6477 - acc: 0.5872 - val_loss: 0.6943 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 141ms/step - loss: 0.6948 - acc: 0.5036 - val_loss: 0.6937 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6934 - acc: 0.5055 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 142ms/step - loss: 0.6941 - acc: 0.4954 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6923 - acc: 0.5074 - val_loss: 0.6675 - val_acc: 0.5967\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6882 - acc: 0.5702 - val_loss: 0.6905 - val_acc: 0.5380\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.7020 - acc: 0.5255 - val_loss: 0.6474 - val_acc: 0.6206\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7036 - acc: 0.5507 - val_loss: 0.6909 - val_acc: 0.5652\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6952 - acc: 0.5467 - val_loss: 0.6962 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7018 - acc: 0.5414 - val_loss: 0.6846 - val_acc: 0.5673\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6825 - acc: 0.5811 - val_loss: 0.6855 - val_acc: 0.5670\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6791 - acc: 0.5883 - val_loss: 0.6842 - val_acc: 0.5671\n","Epoch 1/8\n","63/63 [==============================] - 12s 155ms/step - loss: 0.6928 - acc: 0.5118 - val_loss: 0.6721 - val_acc: 0.5666\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6379 - acc: 0.6333 - val_loss: 0.6870 - val_acc: 0.5186\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6635 - acc: 0.5981 - val_loss: 0.6046 - val_acc: 0.6585\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4500 - acc: 0.8211 - val_loss: 0.6946 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6952 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6934 - acc: 0.5022 - val_loss: 0.6939 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6936 - acc: 0.5051 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6935 - acc: 0.5030 - val_loss: 0.6930 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 154ms/step - loss: 0.7002 - acc: 0.5132 - val_loss: 0.6634 - val_acc: 0.6219\n","Epoch 2/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.6699 - acc: 0.6465 - val_loss: 0.6892 - val_acc: 0.5322\n","Epoch 3/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.6888 - acc: 0.5297 - val_loss: 0.6531 - val_acc: 0.5927\n","Epoch 4/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.6691 - acc: 0.5972 - val_loss: 0.5807 - val_acc: 0.6723\n","Epoch 5/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.5340 - acc: 0.7282 - val_loss: 0.4497 - val_acc: 0.8120\n","Epoch 6/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.3307 - acc: 0.8786 - val_loss: 0.3771 - val_acc: 0.8483\n","Epoch 7/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.1658 - acc: 0.9452 - val_loss: 0.4234 - val_acc: 0.8554\n","Epoch 8/8\n","63/63 [==============================] - 9s 143ms/step - loss: 0.0960 - acc: 0.9746 - val_loss: 0.4173 - val_acc: 0.8542\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6927 - acc: 0.5090 - val_loss: 0.6920 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6859 - acc: 0.5392 - val_loss: 0.6515 - val_acc: 0.6003\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6325 - acc: 0.6702 - val_loss: 0.4950 - val_acc: 0.7542\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3415 - acc: 0.8738 - val_loss: 0.3875 - val_acc: 0.8594\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.1736 - acc: 0.9437 - val_loss: 0.3675 - val_acc: 0.8605\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1047 - acc: 0.9707 - val_loss: 0.4040 - val_acc: 0.8502\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.0839 - acc: 0.9786 - val_loss: 0.4373 - val_acc: 0.8543\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.0582 - acc: 0.9854 - val_loss: 0.4909 - val_acc: 0.8501\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6961 - acc: 0.5071 - val_loss: 0.6912 - val_acc: 0.5085\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6632 - acc: 0.6111 - val_loss: 0.5099 - val_acc: 0.7924\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4243 - acc: 0.8423 - val_loss: 0.6548 - val_acc: 0.7284\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5776 - acc: 0.7270 - val_loss: 0.6343 - val_acc: 0.6605\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5747 - acc: 0.7121 - val_loss: 0.6595 - val_acc: 0.6123\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6496 - acc: 0.6248 - val_loss: 0.6243 - val_acc: 0.6588\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5756 - acc: 0.6989 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6936 - acc: 0.5041 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 155ms/step - loss: 0.6951 - acc: 0.5146 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6887 - acc: 0.5092 - val_loss: 0.6877 - val_acc: 0.5440\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6744 - acc: 0.5994 - val_loss: 0.6042 - val_acc: 0.7052\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5987 - acc: 0.6795 - val_loss: 0.6039 - val_acc: 0.6522\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4961 - acc: 0.7805 - val_loss: 0.4724 - val_acc: 0.7792\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3536 - acc: 0.8668 - val_loss: 0.5326 - val_acc: 0.7754\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3839 - acc: 0.8677 - val_loss: 0.4649 - val_acc: 0.8307\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.2912 - acc: 0.9007 - val_loss: 0.5376 - val_acc: 0.8071\n","Epoch 1/8\n","63/63 [==============================] - 13s 156ms/step - loss: 0.6917 - acc: 0.5174 - val_loss: 0.6872 - val_acc: 0.5142\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6877 - acc: 0.5351 - val_loss: 0.6769 - val_acc: 0.5666\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6481 - acc: 0.6024 - val_loss: 0.4222 - val_acc: 0.8334\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5193 - acc: 0.7467 - val_loss: 0.4939 - val_acc: 0.7894\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6272 - acc: 0.6397 - val_loss: 0.7810 - val_acc: 0.5756\n","Epoch 6/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5952 - acc: 0.6616 - val_loss: 0.6209 - val_acc: 0.6339\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5640 - acc: 0.7109 - val_loss: 0.4834 - val_acc: 0.8164\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6250 - acc: 0.6943 - val_loss: 0.6838 - val_acc: 0.5016\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6952 - acc: 0.5106 - val_loss: 0.6724 - val_acc: 0.5391\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6708 - acc: 0.5873 - val_loss: 0.6004 - val_acc: 0.6968\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5531 - acc: 0.7390 - val_loss: 0.6870 - val_acc: 0.5221\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6849 - acc: 0.5733 - val_loss: 0.6912 - val_acc: 0.5164\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6899 - acc: 0.5161 - val_loss: 0.6910 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6894 - acc: 0.5134 - val_loss: 0.6907 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6893 - acc: 0.5037 - val_loss: 0.6910 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6887 - acc: 0.5108 - val_loss: 0.6906 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 156ms/step - loss: 0.6956 - acc: 0.5137 - val_loss: 0.6426 - val_acc: 0.6325\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6783 - acc: 0.6129 - val_loss: 0.6824 - val_acc: 0.5813\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6322 - acc: 0.6588 - val_loss: 0.6616 - val_acc: 0.5975\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5768 - acc: 0.7163 - val_loss: 0.5282 - val_acc: 0.7550\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.4440 - acc: 0.8217 - val_loss: 0.5187 - val_acc: 0.7534\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4975 - acc: 0.7709 - val_loss: 0.6873 - val_acc: 0.5266\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6864 - acc: 0.5139 - val_loss: 0.6806 - val_acc: 0.5294\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6751 - acc: 0.5764 - val_loss: 0.6852 - val_acc: 0.5240\n","Epoch 1/8\n","63/63 [==============================] - 12s 155ms/step - loss: 0.6923 - acc: 0.5127 - val_loss: 0.6726 - val_acc: 0.5407\n","Epoch 2/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6412 - acc: 0.5985 - val_loss: 0.5499 - val_acc: 0.6445\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5467 - acc: 0.7263 - val_loss: 0.6879 - val_acc: 0.6339\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5828 - acc: 0.6839 - val_loss: 0.5065 - val_acc: 0.7825\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5495 - acc: 0.7454 - val_loss: 0.5611 - val_acc: 0.7186\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5276 - acc: 0.7492 - val_loss: 0.5593 - val_acc: 0.7200\n","Epoch 7/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.4869 - acc: 0.8040 - val_loss: 0.5369 - val_acc: 0.7772\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5253 - acc: 0.7607 - val_loss: 0.6622 - val_acc: 0.5799\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6931 - acc: 0.5090 - val_loss: 0.6470 - val_acc: 0.5991\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6278 - acc: 0.6314 - val_loss: 0.5672 - val_acc: 0.7507\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4824 - acc: 0.7932 - val_loss: 0.6324 - val_acc: 0.6338\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6118 - acc: 0.6340 - val_loss: 0.6556 - val_acc: 0.5654\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6178 - acc: 0.6580 - val_loss: 0.6106 - val_acc: 0.6482\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5367 - acc: 0.7250 - val_loss: 0.6605 - val_acc: 0.6026\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6373 - acc: 0.6340 - val_loss: 0.6555 - val_acc: 0.6507\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5802 - acc: 0.6976 - val_loss: 0.6283 - val_acc: 0.6464\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6997 - acc: 0.5057 - val_loss: 0.6867 - val_acc: 0.5705\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.7025 - acc: 0.5463 - val_loss: 0.6884 - val_acc: 0.5907\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6860 - acc: 0.5702 - val_loss: 0.7848 - val_acc: 0.5218\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6305 - acc: 0.6799 - val_loss: 0.5913 - val_acc: 0.7351\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4703 - acc: 0.8040 - val_loss: 0.6500 - val_acc: 0.6511\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5405 - acc: 0.7352 - val_loss: 0.4640 - val_acc: 0.7662\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3098 - acc: 0.8816 - val_loss: 0.4244 - val_acc: 0.8315\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.2353 - acc: 0.9213 - val_loss: 0.4062 - val_acc: 0.8505\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6912 - acc: 0.5129 - val_loss: 0.6841 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6793 - acc: 0.5393 - val_loss: 0.6795 - val_acc: 0.5291\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6606 - acc: 0.5916 - val_loss: 0.6438 - val_acc: 0.6026\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5614 - acc: 0.6936 - val_loss: 0.6585 - val_acc: 0.5790\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5976 - acc: 0.6515 - val_loss: 0.4841 - val_acc: 0.8150\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4452 - acc: 0.8029 - val_loss: 0.5615 - val_acc: 0.7866\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3348 - acc: 0.8848 - val_loss: 0.5044 - val_acc: 0.8247\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.4026 - acc: 0.8340 - val_loss: 0.4032 - val_acc: 0.8426\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6915 - acc: 0.5132 - val_loss: 0.6902 - val_acc: 0.5054\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6790 - acc: 0.5527 - val_loss: 0.7003 - val_acc: 0.5026\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6851 - acc: 0.5501 - val_loss: 0.6588 - val_acc: 0.5878\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6164 - acc: 0.6299 - val_loss: 0.4535 - val_acc: 0.8284\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4042 - acc: 0.8497 - val_loss: 0.4291 - val_acc: 0.8155\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.2614 - acc: 0.9087 - val_loss: 0.4060 - val_acc: 0.8571\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.1701 - acc: 0.9476 - val_loss: 0.3752 - val_acc: 0.8583\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.1086 - acc: 0.9695 - val_loss: 0.4064 - val_acc: 0.8525\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6930 - acc: 0.5091 - val_loss: 0.6677 - val_acc: 0.5760\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6799 - acc: 0.5932 - val_loss: 0.6822 - val_acc: 0.5510\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6458 - acc: 0.6302 - val_loss: 0.6725 - val_acc: 0.5378\n","Epoch 4/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6796 - acc: 0.5279 - val_loss: 0.6835 - val_acc: 0.5196\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6795 - acc: 0.5256 - val_loss: 0.6825 - val_acc: 0.5205\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6773 - acc: 0.5301 - val_loss: 0.6938 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6924 - acc: 0.5132 - val_loss: 0.6911 - val_acc: 0.5031\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6901 - acc: 0.5327 - val_loss: 0.6892 - val_acc: 0.5197\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.7086 - acc: 0.5102 - val_loss: 0.8075 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.7224 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6960 - acc: 0.4986 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6953 - acc: 0.4964 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6938 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6939 - acc: 0.4988 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6933 - acc: 0.5061 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6938 - acc: 0.4945 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.7029 - acc: 0.5148 - val_loss: 0.6850 - val_acc: 0.5749\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6432 - acc: 0.6496 - val_loss: 0.5718 - val_acc: 0.7120\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6304 - acc: 0.6884 - val_loss: 0.6678 - val_acc: 0.6411\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6489 - acc: 0.6340 - val_loss: 0.6793 - val_acc: 0.5268\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6982 - acc: 0.5019 - val_loss: 0.6934 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6935 - acc: 0.5137 - val_loss: 0.6922 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6938 - acc: 0.5128 - val_loss: 0.6904 - val_acc: 0.5160\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6905 - acc: 0.5335 - val_loss: 0.6972 - val_acc: 0.5159\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6983 - acc: 0.5070 - val_loss: 0.6896 - val_acc: 0.5255\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6804 - acc: 0.5584 - val_loss: 0.6207 - val_acc: 0.6232\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5909 - acc: 0.6492 - val_loss: 0.6254 - val_acc: 0.5956\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5385 - acc: 0.7133 - val_loss: 0.6961 - val_acc: 0.7014\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5340 - acc: 0.7617 - val_loss: 0.6170 - val_acc: 0.6925\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4036 - acc: 0.8335 - val_loss: 0.4604 - val_acc: 0.8200\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3395 - acc: 0.8738 - val_loss: 0.4545 - val_acc: 0.8177\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.2968 - acc: 0.8949 - val_loss: 0.4926 - val_acc: 0.8079\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6928 - acc: 0.5125 - val_loss: 0.5564 - val_acc: 0.7487\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6011 - acc: 0.6723 - val_loss: 0.5668 - val_acc: 0.7494\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4255 - acc: 0.8343 - val_loss: 1.4463 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.7390 - acc: 0.5179 - val_loss: 0.6878 - val_acc: 0.5230\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6843 - acc: 0.5297 - val_loss: 0.6877 - val_acc: 0.5231\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6859 - acc: 0.5269 - val_loss: 0.6877 - val_acc: 0.5231\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6854 - acc: 0.5300 - val_loss: 0.6879 - val_acc: 0.5232\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6841 - acc: 0.5318 - val_loss: 0.6882 - val_acc: 0.5233\n","Epoch 1/8\n","63/63 [==============================] - 13s 164ms/step - loss: 0.6963 - acc: 0.5059 - val_loss: 0.7381 - val_acc: 0.5024\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.7021 - acc: 0.5295 - val_loss: 0.6814 - val_acc: 0.5622\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6350 - acc: 0.6543 - val_loss: 0.5201 - val_acc: 0.7269\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5001 - acc: 0.7747 - val_loss: 0.5479 - val_acc: 0.7680\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4893 - acc: 0.8052 - val_loss: 0.5600 - val_acc: 0.7660\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4699 - acc: 0.8173 - val_loss: 0.5044 - val_acc: 0.7912\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3730 - acc: 0.8644 - val_loss: 0.4943 - val_acc: 0.8046\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4577 - acc: 0.7868 - val_loss: 0.6774 - val_acc: 0.5920\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6904 - acc: 0.5226 - val_loss: 0.6594 - val_acc: 0.5857\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6665 - acc: 0.6083 - val_loss: 0.6735 - val_acc: 0.5661\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6267 - acc: 0.6343 - val_loss: 0.6283 - val_acc: 0.6197\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5366 - acc: 0.7297 - val_loss: 0.6055 - val_acc: 0.6261\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6024 - acc: 0.6571 - val_loss: 0.6938 - val_acc: 0.5672\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5814 - acc: 0.6753 - val_loss: 0.6057 - val_acc: 0.6504\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4281 - acc: 0.7841 - val_loss: 0.4046 - val_acc: 0.8329\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4599 - acc: 0.7577 - val_loss: 0.4491 - val_acc: 0.8082\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.7008 - acc: 0.5161 - val_loss: 0.6816 - val_acc: 0.5704\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6661 - acc: 0.6100 - val_loss: 0.6007 - val_acc: 0.6674\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5688 - acc: 0.7334 - val_loss: 0.5018 - val_acc: 0.7822\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4393 - acc: 0.8282 - val_loss: 0.5396 - val_acc: 0.7787\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5016 - acc: 0.7712 - val_loss: 0.5925 - val_acc: 0.6764\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5505 - acc: 0.7099 - val_loss: 0.5764 - val_acc: 0.6974\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5506 - acc: 0.7159 - val_loss: 0.6018 - val_acc: 0.6462\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5978 - acc: 0.6378 - val_loss: 0.5460 - val_acc: 0.7687\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6940 - acc: 0.5207 - val_loss: 0.6940 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6926 - acc: 0.5267 - val_loss: 0.6563 - val_acc: 0.5960\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6488 - acc: 0.5963 - val_loss: 0.5768 - val_acc: 0.6621\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6399 - acc: 0.6005 - val_loss: 0.6540 - val_acc: 0.6073\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6193 - acc: 0.6666 - val_loss: 0.6862 - val_acc: 0.5635\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6767 - acc: 0.5551 - val_loss: 0.6642 - val_acc: 0.5803\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6578 - acc: 0.5853 - val_loss: 0.6728 - val_acc: 0.5799\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6411 - acc: 0.6038 - val_loss: 0.6895 - val_acc: 0.5662\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6967 - acc: 0.5109 - val_loss: 0.6858 - val_acc: 0.5640\n","Epoch 2/8\n","63/63 [==============================] - 9s 144ms/step - loss: 0.6839 - acc: 0.5845 - val_loss: 0.6643 - val_acc: 0.5598\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6316 - acc: 0.6229 - val_loss: 0.6483 - val_acc: 0.7207\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5182 - acc: 0.7749 - val_loss: 0.6706 - val_acc: 0.5674\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5640 - acc: 0.6810 - val_loss: 0.4761 - val_acc: 0.8104\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4002 - acc: 0.8455 - val_loss: 0.4671 - val_acc: 0.8146\n","Epoch 7/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.3010 - acc: 0.8932 - val_loss: 0.7734 - val_acc: 0.6666\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6408 - acc: 0.6622 - val_loss: 0.5052 - val_acc: 0.7851\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6924 - acc: 0.5087 - val_loss: 0.6886 - val_acc: 0.5264\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6528 - acc: 0.6018 - val_loss: 0.7561 - val_acc: 0.6054\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6984 - acc: 0.5472 - val_loss: 0.6763 - val_acc: 0.5602\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6205 - acc: 0.6425 - val_loss: 0.7227 - val_acc: 0.6880\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6748 - acc: 0.6525 - val_loss: 0.6595 - val_acc: 0.6164\n","Epoch 6/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6499 - acc: 0.6283 - val_loss: 0.6202 - val_acc: 0.6316\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6151 - acc: 0.6477 - val_loss: 0.6850 - val_acc: 0.5158\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6886 - acc: 0.5102 - val_loss: 0.6862 - val_acc: 0.5840\n","Epoch 1/8\n","63/63 [==============================] - 13s 166ms/step - loss: 0.7009 - acc: 0.5137 - val_loss: 0.6894 - val_acc: 0.5043\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6820 - acc: 0.5719 - val_loss: 0.7007 - val_acc: 0.5946\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6344 - acc: 0.6421 - val_loss: 0.6677 - val_acc: 0.5557\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6533 - acc: 0.5738 - val_loss: 0.6868 - val_acc: 0.5295\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6199 - acc: 0.6372 - val_loss: 0.8496 - val_acc: 0.5639\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5571 - acc: 0.7239 - val_loss: 0.4990 - val_acc: 0.7742\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4288 - acc: 0.7951 - val_loss: 0.6492 - val_acc: 0.5884\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5440 - acc: 0.7174 - val_loss: 0.7120 - val_acc: 0.5330\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6988 - acc: 0.5085 - val_loss: 0.6911 - val_acc: 0.5135\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6890 - acc: 0.5247 - val_loss: 0.6894 - val_acc: 0.5195\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6764 - acc: 0.5649 - val_loss: 0.5253 - val_acc: 0.7772\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4006 - acc: 0.8407 - val_loss: 0.3584 - val_acc: 0.8523\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6968 - acc: 0.5090 - val_loss: 0.6888 - val_acc: 0.5882\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6752 - acc: 0.6150 - val_loss: 0.6752 - val_acc: 0.5415\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6698 - acc: 0.5748 - val_loss: 0.6619 - val_acc: 0.5283\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6348 - acc: 0.6235 - val_loss: 0.4804 - val_acc: 0.8101\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3963 - acc: 0.8356 - val_loss: 0.4198 - val_acc: 0.8104\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6182 - acc: 0.6577 - val_loss: 0.6174 - val_acc: 0.7190\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5515 - acc: 0.7552 - val_loss: 0.6264 - val_acc: 0.6497\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5814 - acc: 0.7122 - val_loss: 0.5089 - val_acc: 0.8008\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6935 - acc: 0.5050 - val_loss: 0.6977 - val_acc: 0.4450\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6880 - acc: 0.5148 - val_loss: 0.5725 - val_acc: 0.7130\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5896 - acc: 0.7452 - val_loss: 0.6741 - val_acc: 0.5430\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6222 - acc: 0.6246 - val_loss: 0.6584 - val_acc: 0.7455\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3890 - acc: 0.8543 - val_loss: 0.3700 - val_acc: 0.8510\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.2052 - acc: 0.9294 - val_loss: 0.4156 - val_acc: 0.8422\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1530 - acc: 0.9512 - val_loss: 0.4076 - val_acc: 0.8600\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.0794 - acc: 0.9769 - val_loss: 0.4903 - val_acc: 0.8573\n","Epoch 1/8\n","63/63 [==============================] - 13s 159ms/step - loss: 0.6938 - acc: 0.5051 - val_loss: 0.6864 - val_acc: 0.5413\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6939 - acc: 0.5577 - val_loss: 0.6948 - val_acc: 0.5040\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6251 - acc: 0.6095 - val_loss: 0.5030 - val_acc: 0.8133\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3410 - acc: 0.8726 - val_loss: 0.3440 - val_acc: 0.8612\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6944 - acc: 0.5322 - val_loss: 0.6983 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.7005 - acc: 0.5027 - val_loss: 0.6917 - val_acc: 0.5867\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6916 - acc: 0.5242 - val_loss: 0.6904 - val_acc: 0.5644\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6723 - acc: 0.6255 - val_loss: 0.6247 - val_acc: 0.6564\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5467 - acc: 0.7230 - val_loss: 0.6946 - val_acc: 0.4970\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6599 - acc: 0.5816 - val_loss: 0.6773 - val_acc: 0.5039\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6487 - acc: 0.6259 - val_loss: 0.9324 - val_acc: 0.5031\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6580 - acc: 0.6398 - val_loss: 0.6128 - val_acc: 0.6395\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6938 - acc: 0.5145 - val_loss: 0.7002 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6932 - acc: 0.5222 - val_loss: 0.6731 - val_acc: 0.5508\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6689 - acc: 0.5673 - val_loss: 0.6653 - val_acc: 0.5700\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6584 - acc: 0.6334 - val_loss: 0.7112 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.7064 - acc: 0.5015 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6912 - acc: 0.5270 - val_loss: 0.7074 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6937 - acc: 0.5408 - val_loss: 0.6980 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6948 - acc: 0.5064 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6985 - acc: 0.5155 - val_loss: 0.6909 - val_acc: 0.5152\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6540 - acc: 0.6001 - val_loss: 0.4989 - val_acc: 0.7706\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5205 - acc: 0.7623 - val_loss: 0.6290 - val_acc: 0.5741\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6631 - acc: 0.5969 - val_loss: 0.6735 - val_acc: 0.5336\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6547 - acc: 0.5653 - val_loss: 0.6691 - val_acc: 0.5430\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6554 - acc: 0.5555 - val_loss: 0.6584 - val_acc: 0.5781\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6641 - acc: 0.5581 - val_loss: 0.6725 - val_acc: 0.5892\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6558 - acc: 0.6128 - val_loss: 0.6427 - val_acc: 0.6078\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6988 - acc: 0.5194 - val_loss: 0.6351 - val_acc: 0.6656\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6652 - acc: 0.6178 - val_loss: 0.6705 - val_acc: 0.5804\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6344 - acc: 0.6347 - val_loss: 0.5113 - val_acc: 0.7994\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4812 - acc: 0.7791 - val_loss: 0.6421 - val_acc: 0.5834\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5116 - acc: 0.7470 - val_loss: 0.6502 - val_acc: 0.5341\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5212 - acc: 0.7533 - val_loss: 0.5555 - val_acc: 0.7740\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4016 - acc: 0.8538 - val_loss: 0.5757 - val_acc: 0.6950\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6177 - acc: 0.6388 - val_loss: 0.7244 - val_acc: 0.5003\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6947 - acc: 0.5104 - val_loss: 0.6891 - val_acc: 0.5433\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6822 - acc: 0.5630 - val_loss: 0.6973 - val_acc: 0.5076\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6702 - acc: 0.6227 - val_loss: 0.6245 - val_acc: 0.6159\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4891 - acc: 0.7445 - val_loss: 0.4215 - val_acc: 0.8285\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5434 - acc: 0.7529 - val_loss: 0.6563 - val_acc: 0.5817\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5893 - acc: 0.6613 - val_loss: 0.4452 - val_acc: 0.8178\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4208 - acc: 0.8420 - val_loss: 0.6653 - val_acc: 0.6047\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6366 - acc: 0.7329 - val_loss: 0.6815 - val_acc: 0.5726\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6916 - acc: 0.5105 - val_loss: 0.6493 - val_acc: 0.5544\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6490 - acc: 0.6327 - val_loss: 0.5838 - val_acc: 0.7222\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4438 - acc: 0.8067 - val_loss: 0.3722 - val_acc: 0.8497\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.2132 - acc: 0.9305 - val_loss: 0.3938 - val_acc: 0.8622\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.1176 - acc: 0.9670 - val_loss: 0.3655 - val_acc: 0.8606\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.0748 - acc: 0.9811 - val_loss: 0.6667 - val_acc: 0.8428\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.0514 - acc: 0.9876 - val_loss: 0.5397 - val_acc: 0.8543\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.0384 - acc: 0.9913 - val_loss: 0.5827 - val_acc: 0.8483\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.7062 - acc: 0.5051 - val_loss: 0.6741 - val_acc: 0.5977\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6891 - acc: 0.5271 - val_loss: 0.6848 - val_acc: 0.5438\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6807 - acc: 0.5777 - val_loss: 0.6669 - val_acc: 0.5808\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6582 - acc: 0.6222 - val_loss: 0.5329 - val_acc: 0.7460\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3987 - acc: 0.8390 - val_loss: 0.5177 - val_acc: 0.7844\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.2933 - acc: 0.8903 - val_loss: 0.3835 - val_acc: 0.8472\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.2014 - acc: 0.9399 - val_loss: 0.4136 - val_acc: 0.8404\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.1322 - acc: 0.9638 - val_loss: 0.4450 - val_acc: 0.8540\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6951 - acc: 0.5228 - val_loss: 0.6284 - val_acc: 0.6453\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4541 - acc: 0.8034 - val_loss: 0.3452 - val_acc: 0.8625\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6954 - acc: 0.5161 - val_loss: 0.6871 - val_acc: 0.5761\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6766 - acc: 0.5767 - val_loss: 0.6752 - val_acc: 0.5496\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5934 - acc: 0.6625 - val_loss: 0.4696 - val_acc: 0.8164\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5375 - acc: 0.7235 - val_loss: 0.5173 - val_acc: 0.8142\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4072 - acc: 0.8537 - val_loss: 0.5836 - val_acc: 0.6451\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4383 - acc: 0.8318 - val_loss: 0.6286 - val_acc: 0.6451\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6184 - acc: 0.6524 - val_loss: 0.6220 - val_acc: 0.6318\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6055 - acc: 0.6471 - val_loss: 0.6202 - val_acc: 0.6338\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.7015 - acc: 0.5022 - val_loss: 0.6645 - val_acc: 0.5776\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6970 - acc: 0.5507 - val_loss: 0.6308 - val_acc: 0.6446\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5523 - acc: 0.7515 - val_loss: 0.5562 - val_acc: 0.6653\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4665 - acc: 0.8011 - val_loss: 0.5745 - val_acc: 0.7480\n","Epoch 5/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.5031 - acc: 0.7911 - val_loss: 0.5491 - val_acc: 0.7438\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5174 - acc: 0.7550 - val_loss: 0.5567 - val_acc: 0.7354\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4793 - acc: 0.7968 - val_loss: 0.5703 - val_acc: 0.7537\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5189 - acc: 0.7799 - val_loss: 0.6916 - val_acc: 0.5234\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6930 - acc: 0.5065 - val_loss: 0.6733 - val_acc: 0.5977\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6668 - acc: 0.6002 - val_loss: 0.6392 - val_acc: 0.6082\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5781 - acc: 0.6904 - val_loss: 0.5055 - val_acc: 0.7653\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4280 - acc: 0.8257 - val_loss: 0.5792 - val_acc: 0.7895\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4147 - acc: 0.8384 - val_loss: 0.5892 - val_acc: 0.7096\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6057 - acc: 0.6748 - val_loss: 0.6381 - val_acc: 0.6084\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6272 - acc: 0.6473 - val_loss: 0.6085 - val_acc: 0.6277\n","Epoch 8/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.4043 - acc: 0.8174 - val_loss: 0.3771 - val_acc: 0.8464\n","Epoch 1/8\n","63/63 [==============================] - 12s 160ms/step - loss: 0.6946 - acc: 0.5058 - val_loss: 0.6949 - val_acc: 0.4975\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6923 - acc: 0.5124 - val_loss: 0.6390 - val_acc: 0.6067\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6213 - acc: 0.6649 - val_loss: 0.6885 - val_acc: 0.5050\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6791 - acc: 0.5625 - val_loss: 0.5079 - val_acc: 0.8029\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5240 - acc: 0.7579 - val_loss: 0.5398 - val_acc: 0.7833\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5278 - acc: 0.7395 - val_loss: 0.5123 - val_acc: 0.7940\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4812 - acc: 0.8050 - val_loss: 0.5081 - val_acc: 0.7710\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4484 - acc: 0.8239 - val_loss: 0.5295 - val_acc: 0.7862\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6959 - acc: 0.5160 - val_loss: 0.6916 - val_acc: 0.5268\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6724 - acc: 0.6045 - val_loss: 0.6062 - val_acc: 0.6487\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4599 - acc: 0.7857 - val_loss: 0.4004 - val_acc: 0.8393\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.2317 - acc: 0.9239 - val_loss: 0.3498 - val_acc: 0.8618\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6933 - acc: 0.5144 - val_loss: 0.6916 - val_acc: 0.5539\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6830 - acc: 0.5335 - val_loss: 0.6690 - val_acc: 0.5790\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6332 - acc: 0.6667 - val_loss: 0.5338 - val_acc: 0.7579\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4920 - acc: 0.7893 - val_loss: 0.4268 - val_acc: 0.8232\n","Epoch 5/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.2379 - acc: 0.9162 - val_loss: 0.3502 - val_acc: 0.8678\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 162ms/step - loss: 0.6954 - acc: 0.5046 - val_loss: 0.6901 - val_acc: 0.5319\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6914 - acc: 0.5594 - val_loss: 0.6921 - val_acc: 0.5008\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6840 - acc: 0.5580 - val_loss: 0.7355 - val_acc: 0.5045\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6686 - acc: 0.5731 - val_loss: 0.6461 - val_acc: 0.6054\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5987 - acc: 0.6735 - val_loss: 0.7072 - val_acc: 0.5656\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6654 - acc: 0.6019 - val_loss: 0.6968 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6960 - acc: 0.4972 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6936 - acc: 0.5047 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6941 - acc: 0.5120 - val_loss: 0.6863 - val_acc: 0.5397\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6823 - acc: 0.5518 - val_loss: 0.6663 - val_acc: 0.6539\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5828 - acc: 0.7094 - val_loss: 0.4616 - val_acc: 0.8041\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3527 - acc: 0.8737 - val_loss: 0.3750 - val_acc: 0.8535\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1827 - acc: 0.9422 - val_loss: 0.3369 - val_acc: 0.8629\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6920 - acc: 0.5203 - val_loss: 0.6855 - val_acc: 0.5450\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6901 - acc: 0.5208 - val_loss: 0.6877 - val_acc: 0.5778\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6677 - acc: 0.6164 - val_loss: 0.5669 - val_acc: 0.7602\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5209 - acc: 0.7219 - val_loss: 0.4635 - val_acc: 0.8180\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.2977 - acc: 0.8896 - val_loss: 0.3512 - val_acc: 0.8634\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 166ms/step - loss: 0.6936 - acc: 0.5079 - val_loss: 0.7519 - val_acc: 0.5206\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6534 - acc: 0.6266 - val_loss: 0.4479 - val_acc: 0.8007\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.5417 - acc: 0.7666 - val_loss: 0.6588 - val_acc: 0.6297\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6522 - acc: 0.6485 - val_loss: 0.6631 - val_acc: 0.6264\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6477 - acc: 0.6490 - val_loss: 0.6742 - val_acc: 0.5933\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6804 - acc: 0.5626 - val_loss: 0.6326 - val_acc: 0.5966\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5599 - acc: 0.7100 - val_loss: 0.4628 - val_acc: 0.8151\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3771 - acc: 0.8632 - val_loss: 0.4370 - val_acc: 0.7846\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6956 - acc: 0.5099 - val_loss: 0.6808 - val_acc: 0.5608\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6619 - acc: 0.6166 - val_loss: 0.6202 - val_acc: 0.6395\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5974 - acc: 0.6752 - val_loss: 0.6608 - val_acc: 0.5678\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5467 - acc: 0.7219 - val_loss: 0.3862 - val_acc: 0.8450\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.2606 - acc: 0.9049 - val_loss: 0.3893 - val_acc: 0.8542\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.1940 - acc: 0.9368 - val_loss: 0.4710 - val_acc: 0.8494\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.1739 - acc: 0.9499 - val_loss: 0.3880 - val_acc: 0.8576\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.1078 - acc: 0.9708 - val_loss: 0.4228 - val_acc: 0.8550\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6935 - acc: 0.5104 - val_loss: 0.7045 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6904 - acc: 0.5322 - val_loss: 0.6765 - val_acc: 0.5977\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6668 - acc: 0.6025 - val_loss: 0.6820 - val_acc: 0.5954\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6721 - acc: 0.5944 - val_loss: 0.7896 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7088 - acc: 0.4954 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6942 - acc: 0.5051 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6946 - acc: 0.4907 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6938 - acc: 0.4975 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 159ms/step - loss: 0.6944 - acc: 0.5135 - val_loss: 0.6922 - val_acc: 0.5007\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6927 - acc: 0.5404 - val_loss: 0.6752 - val_acc: 0.5674\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6450 - acc: 0.6400 - val_loss: 0.6963 - val_acc: 0.5036\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6900 - acc: 0.5457 - val_loss: 0.6433 - val_acc: 0.6697\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6257 - acc: 0.6520 - val_loss: 0.4564 - val_acc: 0.8114\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3866 - acc: 0.8506 - val_loss: 0.4556 - val_acc: 0.8228\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3300 - acc: 0.8844 - val_loss: 0.4338 - val_acc: 0.8404\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3052 - acc: 0.8822 - val_loss: 0.4102 - val_acc: 0.8443\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6933 - acc: 0.5098 - val_loss: 0.6768 - val_acc: 0.5846\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6047 - acc: 0.6769 - val_loss: 0.5946 - val_acc: 0.7764\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5064 - acc: 0.7928 - val_loss: 0.4336 - val_acc: 0.8492\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.2373 - acc: 0.9234 - val_loss: 0.3449 - val_acc: 0.8575\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6955 - acc: 0.4992 - val_loss: 0.6894 - val_acc: 0.5161\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7001 - acc: 0.5386 - val_loss: 0.6715 - val_acc: 0.5650\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6208 - acc: 0.6631 - val_loss: 0.7862 - val_acc: 0.5409\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.7213 - acc: 0.5305 - val_loss: 0.5271 - val_acc: 0.7261\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.5634 - acc: 0.6987 - val_loss: 0.6806 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6793 - acc: 0.5175 - val_loss: 0.6748 - val_acc: 0.5323\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6721 - acc: 0.5280 - val_loss: 0.6006 - val_acc: 0.6637\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5510 - acc: 0.7578 - val_loss: 0.6365 - val_acc: 0.7582\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6952 - acc: 0.5043 - val_loss: 0.6756 - val_acc: 0.5254\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7043 - acc: 0.5307 - val_loss: 0.6666 - val_acc: 0.6202\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6221 - acc: 0.6610 - val_loss: 0.5597 - val_acc: 0.7170\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6202 - acc: 0.6661 - val_loss: 0.6677 - val_acc: 0.6014\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6450 - acc: 0.6320 - val_loss: 0.6698 - val_acc: 0.6044\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6530 - acc: 0.6350 - val_loss: 0.6453 - val_acc: 0.6624\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5735 - acc: 0.7117 - val_loss: 0.6018 - val_acc: 0.6578\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6107 - acc: 0.6327 - val_loss: 0.6851 - val_acc: 0.5830\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6940 - acc: 0.5133 - val_loss: 0.7052 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6876 - acc: 0.5365 - val_loss: 0.6710 - val_acc: 0.6026\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6942 - acc: 0.5927 - val_loss: 0.5525 - val_acc: 0.7551\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4583 - acc: 0.8204 - val_loss: 0.3784 - val_acc: 0.8564\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.2179 - acc: 0.9263 - val_loss: 0.3589 - val_acc: 0.8507\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 156ms/step - loss: 0.6921 - acc: 0.5162 - val_loss: 0.6763 - val_acc: 0.5774\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6846 - acc: 0.5921 - val_loss: 0.6525 - val_acc: 0.5955\n","Epoch 3/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6217 - acc: 0.6389 - val_loss: 0.5452 - val_acc: 0.7290\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4023 - acc: 0.8428 - val_loss: 0.4254 - val_acc: 0.8334\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3306 - acc: 0.8798 - val_loss: 0.5859 - val_acc: 0.6184\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.4389 - acc: 0.8172 - val_loss: 0.6655 - val_acc: 0.5468\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6464 - acc: 0.5687 - val_loss: 0.6546 - val_acc: 0.5716\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6377 - acc: 0.5926 - val_loss: 0.6679 - val_acc: 0.5419\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6999 - acc: 0.5149 - val_loss: 0.6881 - val_acc: 0.5771\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6863 - acc: 0.5733 - val_loss: 0.6541 - val_acc: 0.6897\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6365 - acc: 0.6420 - val_loss: 0.5794 - val_acc: 0.7102\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.3534 - acc: 0.8588 - val_loss: 0.3661 - val_acc: 0.8546\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.1611 - acc: 0.9491 - val_loss: 0.3900 - val_acc: 0.8511\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.0843 - acc: 0.9779 - val_loss: 0.5649 - val_acc: 0.8516\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.0695 - acc: 0.9811 - val_loss: 0.5025 - val_acc: 0.8510\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.0485 - acc: 0.9883 - val_loss: 0.5178 - val_acc: 0.8441\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6918 - acc: 0.5187 - val_loss: 0.6478 - val_acc: 0.6174\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6017 - acc: 0.6881 - val_loss: 0.6446 - val_acc: 0.5924\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5729 - acc: 0.6905 - val_loss: 0.4580 - val_acc: 0.8130\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3809 - acc: 0.8638 - val_loss: 0.5064 - val_acc: 0.7647\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3655 - acc: 0.8625 - val_loss: 0.4938 - val_acc: 0.8251\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3335 - acc: 0.8876 - val_loss: 0.4967 - val_acc: 0.8114\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3082 - acc: 0.9005 - val_loss: 0.5070 - val_acc: 0.7982\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3325 - acc: 0.8917 - val_loss: 0.5406 - val_acc: 0.7932\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6941 - acc: 0.5039 - val_loss: 0.6951 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6943 - acc: 0.5143 - val_loss: 0.6879 - val_acc: 0.5100\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6769 - acc: 0.5590 - val_loss: 0.6668 - val_acc: 0.5700\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6084 - acc: 0.6597 - val_loss: 0.4822 - val_acc: 0.8185\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3712 - acc: 0.8663 - val_loss: 0.6180 - val_acc: 0.7870\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6517 - acc: 0.6099 - val_loss: 0.4682 - val_acc: 0.8148\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4037 - acc: 0.8355 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6774 - acc: 0.5428 - val_loss: 0.6916 - val_acc: 0.5149\n","Epoch 1/8\n","63/63 [==============================] - 13s 166ms/step - loss: 0.6931 - acc: 0.5126 - val_loss: 0.6637 - val_acc: 0.5596\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6431 - acc: 0.6175 - val_loss: 0.4468 - val_acc: 0.8278\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3907 - acc: 0.8517 - val_loss: 0.6911 - val_acc: 0.5063\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6865 - acc: 0.5301 - val_loss: 0.4826 - val_acc: 0.8230\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3740 - acc: 0.8714 - val_loss: 0.3812 - val_acc: 0.8514\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.1998 - acc: 0.9344 - val_loss: 0.3593 - val_acc: 0.8540\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6971 - acc: 0.5148 - val_loss: 0.6900 - val_acc: 0.5854\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6880 - acc: 0.5626 - val_loss: 0.6873 - val_acc: 0.5842\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.7027 - acc: 0.5482 - val_loss: 0.6917 - val_acc: 0.5106\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.7006 - acc: 0.5120 - val_loss: 0.6919 - val_acc: 0.5072\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6890 - acc: 0.5321 - val_loss: 0.6084 - val_acc: 0.6578\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6352 - acc: 0.6433 - val_loss: 0.6782 - val_acc: 0.5692\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6579 - acc: 0.6006 - val_loss: 0.4833 - val_acc: 0.8128\n","Epoch 8/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.5170 - acc: 0.7751 - val_loss: 0.6801 - val_acc: 0.6323\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6928 - acc: 0.5069 - val_loss: 0.6695 - val_acc: 0.5393\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.7326 - acc: 0.5390 - val_loss: 0.6608 - val_acc: 0.5948\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6159 - acc: 0.6707 - val_loss: 0.5766 - val_acc: 0.7245\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6151 - acc: 0.6826 - val_loss: 0.6458 - val_acc: 0.5885\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5465 - acc: 0.7132 - val_loss: 0.5300 - val_acc: 0.8004\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4015 - acc: 0.8528 - val_loss: 0.4678 - val_acc: 0.8274\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4574 - acc: 0.7760 - val_loss: 0.6271 - val_acc: 0.6217\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4494 - acc: 0.7916 - val_loss: 0.6088 - val_acc: 0.7797\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6936 - acc: 0.5014 - val_loss: 0.6773 - val_acc: 0.5330\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6948 - acc: 0.5157 - val_loss: 0.6804 - val_acc: 0.5415\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6670 - acc: 0.6107 - val_loss: 0.6879 - val_acc: 0.5776\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6674 - acc: 0.5726 - val_loss: 0.5709 - val_acc: 0.7038\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6819 - acc: 0.6361 - val_loss: 0.6109 - val_acc: 0.6466\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6687 - acc: 0.6030 - val_loss: 0.6929 - val_acc: 0.5104\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6934 - acc: 0.5051 - val_loss: 0.6917 - val_acc: 0.5738\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6920 - acc: 0.5170 - val_loss: 0.7086 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6981 - acc: 0.5136 - val_loss: 0.6849 - val_acc: 0.5663\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5933 - acc: 0.6967 - val_loss: 0.4232 - val_acc: 0.8390\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.2687 - acc: 0.9075 - val_loss: 0.3316 - val_acc: 0.8599\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.7026 - acc: 0.5117 - val_loss: 0.6904 - val_acc: 0.5469\n","Epoch 2/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6911 - acc: 0.5605 - val_loss: 0.6785 - val_acc: 0.6169\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6626 - acc: 0.6174 - val_loss: 0.5175 - val_acc: 0.7510\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5936 - acc: 0.6998 - val_loss: 0.6418 - val_acc: 0.6091\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5716 - acc: 0.7269 - val_loss: 0.4543 - val_acc: 0.8159\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4471 - acc: 0.8168 - val_loss: 0.5374 - val_acc: 0.8162\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3377 - acc: 0.8722 - val_loss: 0.5028 - val_acc: 0.8015\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3890 - acc: 0.8580 - val_loss: 0.4684 - val_acc: 0.8272\n","Epoch 1/8\n","63/63 [==============================] - 13s 165ms/step - loss: 0.6925 - acc: 0.5102 - val_loss: 0.6783 - val_acc: 0.5881\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6803 - acc: 0.5789 - val_loss: 0.6768 - val_acc: 0.5347\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6707 - acc: 0.5749 - val_loss: 0.6120 - val_acc: 0.7345\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6131 - acc: 0.6669 - val_loss: 0.6919 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6925 - acc: 0.4964 - val_loss: 0.6915 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6912 - acc: 0.5045 - val_loss: 0.6912 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6914 - acc: 0.5062 - val_loss: 0.6910 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6915 - acc: 0.4991 - val_loss: 0.6910 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6951 - acc: 0.5075 - val_loss: 0.6912 - val_acc: 0.5601\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6908 - acc: 0.5582 - val_loss: 0.6838 - val_acc: 0.5751\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6730 - acc: 0.5905 - val_loss: 0.6850 - val_acc: 0.5597\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6774 - acc: 0.5787 - val_loss: 0.6395 - val_acc: 0.6078\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6625 - acc: 0.6299 - val_loss: 0.4409 - val_acc: 0.8219\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4782 - acc: 0.8230 - val_loss: 0.6399 - val_acc: 0.6122\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5082 - acc: 0.7540 - val_loss: 0.5006 - val_acc: 0.7900\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4015 - acc: 0.8347 - val_loss: 0.7532 - val_acc: 0.7627\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6926 - acc: 0.5036 - val_loss: 0.6735 - val_acc: 0.5608\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6723 - acc: 0.6090 - val_loss: 0.5653 - val_acc: 0.7079\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5098 - acc: 0.7741 - val_loss: 0.5467 - val_acc: 0.7426\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5340 - acc: 0.7674 - val_loss: 0.4968 - val_acc: 0.8182\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4814 - acc: 0.8014 - val_loss: 0.6676 - val_acc: 0.5616\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6240 - acc: 0.6106 - val_loss: 0.6658 - val_acc: 0.5691\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5395 - acc: 0.6977 - val_loss: 0.4648 - val_acc: 0.8114\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.2809 - acc: 0.8944 - val_loss: 0.4617 - val_acc: 0.8372\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6984 - acc: 0.5140 - val_loss: 0.6908 - val_acc: 0.5196\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6662 - acc: 0.6064 - val_loss: 0.6088 - val_acc: 0.6601\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4279 - acc: 0.8255 - val_loss: 0.3562 - val_acc: 0.8497\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6931 - acc: 0.5209 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6968 - acc: 0.5644 - val_loss: 0.6675 - val_acc: 0.5764\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6054 - acc: 0.6661 - val_loss: 0.6368 - val_acc: 0.6053\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4785 - acc: 0.7688 - val_loss: 0.3583 - val_acc: 0.8529\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 159ms/step - loss: 0.7082 - acc: 0.5109 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6958 - acc: 0.5013 - val_loss: 0.6914 - val_acc: 0.5346\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6875 - acc: 0.5401 - val_loss: 0.6901 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6846 - acc: 0.5266 - val_loss: 0.6865 - val_acc: 0.5273\n","Epoch 5/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6842 - acc: 0.5214 - val_loss: 0.6845 - val_acc: 0.5278\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6835 - acc: 0.5350 - val_loss: 0.6890 - val_acc: 0.5300\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6818 - acc: 0.5460 - val_loss: 0.6870 - val_acc: 0.5397\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6806 - acc: 0.5467 - val_loss: 0.6757 - val_acc: 0.5604\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6918 - acc: 0.5087 - val_loss: 0.6876 - val_acc: 0.5248\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6605 - acc: 0.5908 - val_loss: 0.5423 - val_acc: 0.7491\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4754 - acc: 0.7905 - val_loss: 0.4542 - val_acc: 0.8130\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4220 - acc: 0.8297 - val_loss: 0.4834 - val_acc: 0.8152\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4579 - acc: 0.7913 - val_loss: 0.6731 - val_acc: 0.5600\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6541 - acc: 0.5872 - val_loss: 0.6491 - val_acc: 0.6152\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5270 - acc: 0.7348 - val_loss: 0.4179 - val_acc: 0.8313\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3364 - acc: 0.8715 - val_loss: 0.4194 - val_acc: 0.8036\n","Epoch 1/8\n","63/63 [==============================] - 12s 160ms/step - loss: 0.6951 - acc: 0.5053 - val_loss: 0.6824 - val_acc: 0.5461\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6926 - acc: 0.5448 - val_loss: 0.6911 - val_acc: 0.5068\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6905 - acc: 0.5015 - val_loss: 0.6906 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6884 - acc: 0.5041 - val_loss: 0.6898 - val_acc: 0.5094\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6875 - acc: 0.5079 - val_loss: 0.6899 - val_acc: 0.5092\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6880 - acc: 0.5064 - val_loss: 0.6901 - val_acc: 0.5085\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6880 - acc: 0.5158 - val_loss: 0.6900 - val_acc: 0.5080\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6870 - acc: 0.5047 - val_loss: 0.6895 - val_acc: 0.5070\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6957 - acc: 0.5086 - val_loss: 0.6793 - val_acc: 0.5352\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6994 - acc: 0.5303 - val_loss: 0.6119 - val_acc: 0.6400\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6242 - acc: 0.6652 - val_loss: 0.4542 - val_acc: 0.8133\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4162 - acc: 0.8380 - val_loss: 0.5637 - val_acc: 0.7346\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5397 - acc: 0.7591 - val_loss: 0.5348 - val_acc: 0.7498\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4119 - acc: 0.8404 - val_loss: 0.5587 - val_acc: 0.7927\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5055 - acc: 0.7711 - val_loss: 0.6451 - val_acc: 0.5945\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4763 - acc: 0.7876 - val_loss: 0.4619 - val_acc: 0.8323\n","Epoch 1/8\n","63/63 [==============================] - 12s 157ms/step - loss: 0.6945 - acc: 0.5306 - val_loss: 0.6715 - val_acc: 0.6070\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6869 - acc: 0.6033 - val_loss: 0.7181 - val_acc: 0.5099\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6600 - acc: 0.5938 - val_loss: 0.7749 - val_acc: 0.4999\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6477 - acc: 0.6104 - val_loss: 0.6936 - val_acc: 0.5000\n","Epoch 5/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6958 - acc: 0.5020 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6943 - acc: 0.5019 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6945 - acc: 0.4952 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6939 - acc: 0.4961 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6918 - acc: 0.5205 - val_loss: 0.6777 - val_acc: 0.5847\n","Epoch 2/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6625 - acc: 0.6036 - val_loss: 0.6607 - val_acc: 0.5615\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5964 - acc: 0.6657 - val_loss: 0.6702 - val_acc: 0.5922\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6676 - acc: 0.5840 - val_loss: 0.6790 - val_acc: 0.5489\n","Epoch 5/8\n","63/63 [==============================] - 10s 154ms/step - loss: 0.6770 - acc: 0.5513 - val_loss: 0.6788 - val_acc: 0.5481\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6730 - acc: 0.5575 - val_loss: 0.6800 - val_acc: 0.5772\n","Epoch 7/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.6677 - acc: 0.5721 - val_loss: 0.6415 - val_acc: 0.6116\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6670 - acc: 0.5700 - val_loss: 0.6934 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6931 - acc: 0.5014 - val_loss: 0.6972 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6918 - acc: 0.5293 - val_loss: 0.6682 - val_acc: 0.5573\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6424 - acc: 0.6242 - val_loss: 0.5018 - val_acc: 0.7927\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3579 - acc: 0.8661 - val_loss: 0.3874 - val_acc: 0.8467\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.2129 - acc: 0.9311 - val_loss: 0.3770 - val_acc: 0.8527\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.1662 - acc: 0.9524 - val_loss: 0.4537 - val_acc: 0.8440\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1568 - acc: 0.9570 - val_loss: 0.4991 - val_acc: 0.8507\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1039 - acc: 0.9708 - val_loss: 0.5062 - val_acc: 0.8497\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6937 - acc: 0.5083 - val_loss: 0.6921 - val_acc: 0.5055\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6894 - acc: 0.5604 - val_loss: 0.6721 - val_acc: 0.5656\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6663 - acc: 0.6171 - val_loss: 0.6733 - val_acc: 0.5882\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6689 - acc: 0.6039 - val_loss: 0.6794 - val_acc: 0.5790\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6684 - acc: 0.6045 - val_loss: 0.6937 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6935 - acc: 0.5091 - val_loss: 0.6816 - val_acc: 0.5815\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6640 - acc: 0.5890 - val_loss: 0.6919 - val_acc: 0.5354\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6886 - acc: 0.5373 - val_loss: 0.6838 - val_acc: 0.5440\n","Epoch 1/8\n","63/63 [==============================] - 13s 158ms/step - loss: 0.6944 - acc: 0.5049 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6922 - acc: 0.5065 - val_loss: 0.6844 - val_acc: 0.5139\n","Epoch 3/8\n","63/63 [==============================] - 9s 145ms/step - loss: 0.6651 - acc: 0.5684 - val_loss: 0.6009 - val_acc: 0.6440\n","Epoch 4/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4763 - acc: 0.7807 - val_loss: 0.5517 - val_acc: 0.7714\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4662 - acc: 0.8056 - val_loss: 0.5767 - val_acc: 0.7134\n","Epoch 6/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.4967 - acc: 0.7889 - val_loss: 0.5293 - val_acc: 0.7848\n","Epoch 7/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.3771 - acc: 0.8601 - val_loss: 0.4491 - val_acc: 0.8327\n","Epoch 8/8\n","63/63 [==============================] - 9s 146ms/step - loss: 0.3170 - acc: 0.8755 - val_loss: 0.5634 - val_acc: 0.7692\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6929 - acc: 0.5153 - val_loss: 0.6947 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7023 - acc: 0.5091 - val_loss: 0.6813 - val_acc: 0.5513\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6828 - acc: 0.5544 - val_loss: 0.6850 - val_acc: 0.5420\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6841 - acc: 0.5463 - val_loss: 0.6850 - val_acc: 0.5412\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6842 - acc: 0.5397 - val_loss: 0.6850 - val_acc: 0.5410\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6838 - acc: 0.5395 - val_loss: 0.6848 - val_acc: 0.5418\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6835 - acc: 0.5386 - val_loss: 0.6842 - val_acc: 0.5422\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6798 - acc: 0.5505 - val_loss: 0.6813 - val_acc: 0.5454\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6954 - acc: 0.5062 - val_loss: 0.6936 - val_acc: 0.5054\n","Epoch 2/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6888 - acc: 0.5498 - val_loss: 0.6843 - val_acc: 0.5687\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6468 - acc: 0.6364 - val_loss: 0.4683 - val_acc: 0.7876\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3528 - acc: 0.8632 - val_loss: 0.3572 - val_acc: 0.8560\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6920 - acc: 0.5099 - val_loss: 0.6900 - val_acc: 0.5446\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6075 - acc: 0.6755 - val_loss: 0.4804 - val_acc: 0.8028\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4464 - acc: 0.8204 - val_loss: 0.6977 - val_acc: 0.5428\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6901 - acc: 0.5222 - val_loss: 0.6895 - val_acc: 0.5216\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6858 - acc: 0.5221 - val_loss: 0.6876 - val_acc: 0.5743\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6853 - acc: 0.5174 - val_loss: 0.6875 - val_acc: 0.5217\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6857 - acc: 0.5232 - val_loss: 0.6885 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6833 - acc: 0.5227 - val_loss: 0.6875 - val_acc: 0.5217\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.6929 - acc: 0.5174 - val_loss: 0.6941 - val_acc: 0.5004\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6550 - acc: 0.5875 - val_loss: 0.6512 - val_acc: 0.7613\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5488 - acc: 0.7408 - val_loss: 0.4329 - val_acc: 0.8017\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5220 - acc: 0.7693 - val_loss: 0.6690 - val_acc: 0.5697\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6763 - acc: 0.5359 - val_loss: 0.6935 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6947 - acc: 0.4986 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6939 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6945 - acc: 0.4993 - val_loss: 0.6947 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 12s 158ms/step - loss: 0.6919 - acc: 0.5185 - val_loss: 0.6064 - val_acc: 0.7468\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.7051 - acc: 0.5442 - val_loss: 0.6926 - val_acc: 0.5000\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6920 - acc: 0.5250 - val_loss: 0.6929 - val_acc: 0.5000\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6935 - acc: 0.5006 - val_loss: 0.6905 - val_acc: 0.5250\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6790 - acc: 0.5554 - val_loss: 0.6344 - val_acc: 0.5235\n","Epoch 6/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6555 - acc: 0.6025 - val_loss: 0.6476 - val_acc: 0.5813\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6960 - acc: 0.5858 - val_loss: 0.6933 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.7012 - acc: 0.5046 - val_loss: 0.6953 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 159ms/step - loss: 0.6928 - acc: 0.5155 - val_loss: 0.6674 - val_acc: 0.5936\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6804 - acc: 0.6092 - val_loss: 0.5955 - val_acc: 0.7819\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5213 - acc: 0.7735 - val_loss: 0.5384 - val_acc: 0.7446\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4691 - acc: 0.8115 - val_loss: 0.5899 - val_acc: 0.7424\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4773 - acc: 0.8122 - val_loss: 0.4656 - val_acc: 0.8124\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3334 - acc: 0.8791 - val_loss: 0.4638 - val_acc: 0.8048\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.3379 - acc: 0.8783 - val_loss: 0.4449 - val_acc: 0.8291\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.3830 - acc: 0.8519 - val_loss: 0.6869 - val_acc: 0.5862\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6964 - acc: 0.5171 - val_loss: 0.6759 - val_acc: 0.5489\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6876 - acc: 0.5447 - val_loss: 0.6976 - val_acc: 0.5000\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6836 - acc: 0.5264 - val_loss: 0.6746 - val_acc: 0.5336\n","Epoch 4/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6573 - acc: 0.5877 - val_loss: 0.6580 - val_acc: 0.6519\n","Epoch 5/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6203 - acc: 0.6316 - val_loss: 0.5081 - val_acc: 0.7482\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.4121 - acc: 0.8315 - val_loss: 0.3929 - val_acc: 0.8522\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.2127 - acc: 0.9316 - val_loss: 0.3676 - val_acc: 0.8633\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.1367 - acc: 0.9605 - val_loss: 0.4040 - val_acc: 0.8587\n","Epoch 1/8\n","63/63 [==============================] - 13s 162ms/step - loss: 0.7005 - acc: 0.5153 - val_loss: 0.6888 - val_acc: 0.5327\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6905 - acc: 0.5670 - val_loss: 0.6721 - val_acc: 0.5530\n","Epoch 3/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.6003 - acc: 0.6575 - val_loss: 0.4813 - val_acc: 0.7898\n","Epoch 4/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.4144 - acc: 0.8377 - val_loss: 0.5948 - val_acc: 0.7109\n","Epoch 5/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.4253 - acc: 0.8347 - val_loss: 0.5390 - val_acc: 0.7592\n","Epoch 6/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.4347 - acc: 0.8343 - val_loss: 0.7454 - val_acc: 0.5499\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6840 - acc: 0.5328 - val_loss: 0.6922 - val_acc: 0.5016\n","Epoch 8/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6925 - acc: 0.5096 - val_loss: 0.6919 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 166ms/step - loss: 0.6933 - acc: 0.5135 - val_loss: 0.6902 - val_acc: 0.5734\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6957 - acc: 0.5597 - val_loss: 0.6668 - val_acc: 0.5488\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6417 - acc: 0.6093 - val_loss: 0.6246 - val_acc: 0.6150\n","Epoch 4/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6858 - acc: 0.6440 - val_loss: 0.6796 - val_acc: 0.5821\n","Epoch 5/8\n","63/63 [==============================] - 10s 153ms/step - loss: 0.6776 - acc: 0.5896 - val_loss: 0.6749 - val_acc: 0.5836\n","Epoch 6/8\n","63/63 [==============================] - 10s 153ms/step - loss: 0.6744 - acc: 0.5916 - val_loss: 0.6738 - val_acc: 0.5848\n","Epoch 7/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.6655 - acc: 0.6103 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 10s 154ms/step - loss: 0.6939 - acc: 0.5068 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 164ms/step - loss: 0.6933 - acc: 0.5164 - val_loss: 0.6787 - val_acc: 0.6050\n","Epoch 2/8\n","63/63 [==============================] - 10s 151ms/step - loss: 0.6787 - acc: 0.6008 - val_loss: 0.5891 - val_acc: 0.6518\n","Epoch 3/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.4754 - acc: 0.7819 - val_loss: 0.5204 - val_acc: 0.7001\n","Epoch 4/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.4123 - acc: 0.8354 - val_loss: 0.5056 - val_acc: 0.7902\n","Epoch 5/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.6067 - acc: 0.7061 - val_loss: 0.4928 - val_acc: 0.7927\n","Epoch 6/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.4118 - acc: 0.8459 - val_loss: 0.4735 - val_acc: 0.8274\n","Epoch 7/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.3265 - acc: 0.8834 - val_loss: 0.4001 - val_acc: 0.8363\n","Epoch 8/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.2711 - acc: 0.9070 - val_loss: 0.4294 - val_acc: 0.8500\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6935 - acc: 0.5214 - val_loss: 0.6805 - val_acc: 0.6035\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6749 - acc: 0.5751 - val_loss: 0.6215 - val_acc: 0.6279\n","Epoch 3/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.5981 - acc: 0.6813 - val_loss: 0.5183 - val_acc: 0.7598\n","Epoch 4/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.4972 - acc: 0.7786 - val_loss: 0.6772 - val_acc: 0.5706\n","Epoch 5/8\n","63/63 [==============================] - 10s 153ms/step - loss: 0.6553 - acc: 0.6165 - val_loss: 0.6313 - val_acc: 0.6009\n","Epoch 6/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.5787 - acc: 0.6757 - val_loss: 0.5962 - val_acc: 0.6352\n","Epoch 7/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.3823 - acc: 0.8114 - val_loss: 0.3601 - val_acc: 0.8494\n","Epoch 8/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.2149 - acc: 0.9266 - val_loss: 0.4063 - val_acc: 0.8519\n","Epoch 1/8\n","63/63 [==============================] - 13s 164ms/step - loss: 0.6929 - acc: 0.5080 - val_loss: 0.5785 - val_acc: 0.7534\n","Epoch 2/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.6056 - acc: 0.7093 - val_loss: 0.6359 - val_acc: 0.6193\n","Epoch 3/8\n","63/63 [==============================] - 10s 151ms/step - loss: 0.5703 - acc: 0.6981 - val_loss: 0.6398 - val_acc: 0.5918\n","Epoch 4/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.7429 - acc: 0.5840 - val_loss: 0.6884 - val_acc: 0.5376\n","Epoch 5/8\n","63/63 [==============================] - 10s 151ms/step - loss: 0.6797 - acc: 0.5416 - val_loss: 0.6853 - val_acc: 0.5377\n","Epoch 6/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6772 - acc: 0.5518 - val_loss: 0.6853 - val_acc: 0.5379\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6774 - acc: 0.5548 - val_loss: 0.6893 - val_acc: 0.5380\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6797 - acc: 0.5535 - val_loss: 0.6850 - val_acc: 0.5380\n","Epoch 1/8\n","63/63 [==============================] - 12s 159ms/step - loss: 0.6922 - acc: 0.5134 - val_loss: 0.6946 - val_acc: 0.5000\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6901 - acc: 0.5346 - val_loss: 0.6741 - val_acc: 0.5516\n","Epoch 3/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6639 - acc: 0.6463 - val_loss: 0.5904 - val_acc: 0.6637\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5150 - acc: 0.7367 - val_loss: 0.5680 - val_acc: 0.7691\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5509 - acc: 0.7336 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 6/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6936 - acc: 0.5048 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6938 - acc: 0.5070 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 8/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6933 - acc: 0.5042 - val_loss: 0.6931 - val_acc: 0.5000\n","Epoch 1/8\n","63/63 [==============================] - 13s 161ms/step - loss: 0.6925 - acc: 0.5038 - val_loss: 0.6771 - val_acc: 0.5663\n","Epoch 2/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.5960 - acc: 0.6724 - val_loss: 0.6515 - val_acc: 0.5872\n","Epoch 3/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.6702 - acc: 0.6172 - val_loss: 0.5990 - val_acc: 0.6408\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.4166 - acc: 0.8200 - val_loss: 0.4139 - val_acc: 0.8365\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5109 - acc: 0.7374 - val_loss: 0.6309 - val_acc: 0.6096\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6902 - acc: 0.6120 - val_loss: 0.6766 - val_acc: 0.5927\n","Epoch 7/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6717 - acc: 0.6070 - val_loss: 0.6758 - val_acc: 0.5928\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6677 - acc: 0.6137 - val_loss: 0.6745 - val_acc: 0.5928\n","Epoch 1/8\n","63/63 [==============================] - 13s 165ms/step - loss: 0.6958 - acc: 0.5017 - val_loss: 0.6922 - val_acc: 0.5001\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6908 - acc: 0.5511 - val_loss: 0.6945 - val_acc: 0.5002\n","Epoch 3/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6942 - acc: 0.5263 - val_loss: 0.6790 - val_acc: 0.5727\n","Epoch 4/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6860 - acc: 0.6147 - val_loss: 0.6674 - val_acc: 0.5902\n","Epoch 5/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5600 - acc: 0.7123 - val_loss: 0.4469 - val_acc: 0.8274\n","Epoch 6/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5622 - acc: 0.7123 - val_loss: 0.5452 - val_acc: 0.7233\n","Epoch 7/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.5667 - acc: 0.7406 - val_loss: 0.6649 - val_acc: 0.6254\n","Epoch 8/8\n","63/63 [==============================] - 9s 147ms/step - loss: 0.6486 - acc: 0.6466 - val_loss: 0.7361 - val_acc: 0.6261\n","Epoch 1/8\n","63/63 [==============================] - 13s 162ms/step - loss: 0.6924 - acc: 0.5126 - val_loss: 0.7365 - val_acc: 0.5844\n","Epoch 2/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.7414 - acc: 0.5350 - val_loss: 0.6681 - val_acc: 0.5614\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6381 - acc: 0.6402 - val_loss: 0.5116 - val_acc: 0.8056\n","Epoch 4/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4638 - acc: 0.8067 - val_loss: 0.6218 - val_acc: 0.6219\n","Epoch 5/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.5784 - acc: 0.7020 - val_loss: 0.6579 - val_acc: 0.6374\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6229 - acc: 0.6746 - val_loss: 0.6038 - val_acc: 0.6602\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.5789 - acc: 0.6911 - val_loss: 0.6277 - val_acc: 0.6106\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6402 - acc: 0.6170 - val_loss: 0.6780 - val_acc: 0.5854\n","Epoch 1/8\n","63/63 [==============================] - 12s 160ms/step - loss: 0.6922 - acc: 0.5037 - val_loss: 0.6937 - val_acc: 0.4957\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6871 - acc: 0.5361 - val_loss: 1.3536 - val_acc: 0.5512\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.7225 - acc: 0.5751 - val_loss: 1.0286 - val_acc: 0.7508\n","Epoch 4/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6099 - acc: 0.6928 - val_loss: 0.5124 - val_acc: 0.8118\n","Epoch 5/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5361 - acc: 0.7455 - val_loss: 0.5500 - val_acc: 0.7344\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5908 - acc: 0.7300 - val_loss: 0.6852 - val_acc: 0.4994\n","Epoch 7/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6881 - acc: 0.5233 - val_loss: 0.6818 - val_acc: 0.5568\n","Epoch 8/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6771 - acc: 0.5668 - val_loss: 0.6837 - val_acc: 0.5569\n","Epoch 1/8\n","63/63 [==============================] - 13s 160ms/step - loss: 0.7048 - acc: 0.5080 - val_loss: 0.6918 - val_acc: 0.5274\n","Epoch 2/8\n","63/63 [==============================] - 9s 148ms/step - loss: 0.6809 - acc: 0.5685 - val_loss: 0.4185 - val_acc: 0.8208\n","Epoch 3/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.3094 - acc: 0.8819 - val_loss: 0.3336 - val_acc: 0.8662\n","\n","Reached 0.34 loss\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6962 - acc: 0.5058 - val_loss: 0.6868 - val_acc: 0.5231\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.6919 - acc: 0.5786 - val_loss: 0.6511 - val_acc: 0.7257\n","Epoch 3/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6978 - acc: 0.5728 - val_loss: 0.6877 - val_acc: 0.4990\n","Epoch 4/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6600 - acc: 0.6105 - val_loss: 0.7271 - val_acc: 0.5614\n","Epoch 5/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6340 - acc: 0.6289 - val_loss: 0.5506 - val_acc: 0.7563\n","Epoch 6/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.5021 - acc: 0.7803 - val_loss: 0.5810 - val_acc: 0.7219\n","Epoch 7/8\n","63/63 [==============================] - 9s 149ms/step - loss: 0.4828 - acc: 0.7730 - val_loss: 0.4053 - val_acc: 0.8426\n","Epoch 8/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.2684 - acc: 0.9055 - val_loss: 0.5955 - val_acc: 0.6444\n","Epoch 1/8\n","63/63 [==============================] - 13s 163ms/step - loss: 0.6963 - acc: 0.5118 - val_loss: 0.6854 - val_acc: 0.5382\n","Epoch 2/8\n","63/63 [==============================] - 9s 150ms/step - loss: 0.7094 - acc: 0.5643 - val_loss: 0.6632 - val_acc: 0.5654\n","Epoch 3/8\n","63/63 [==============================] - 9s 151ms/step - loss: 0.6153 - acc: 0.6438 - val_loss: 0.4164 - val_acc: 0.8385\n","Epoch 4/8\n","63/63 [==============================] - 10s 152ms/step - loss: 0.2868 - acc: 0.8915 - val_loss: 0.3238 - val_acc: 0.8647\n","\n","Reached 0.34 loss\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DrRb6_yVne6K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618140691598,"user_tz":-480,"elapsed":2932,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}},"outputId":"094bc6d0-e5a9-44c6-f31d-afc3ccd17238"},"source":["# del model\n","model = get_LSTM(max_len)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_12\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (InputLayer)           [(None, 200)]             0         \n","_________________________________________________________________\n","embeddings_layer (Embedding) (None, 200, 50)           691800    \n","_________________________________________________________________\n","lstm_24 (LSTM)               (None, 200, 256)          314368    \n","_________________________________________________________________\n","lstm_25 (LSTM)               (None, 256)               525312    \n","_________________________________________________________________\n","FC1 (Dense)                  (None, 64)                16448     \n","_________________________________________________________________\n","output (Dense)               (None, 1)                 65        \n","=================================================================\n","Total params: 1,547,993\n","Trainable params: 1,547,993\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdN3TkmwnkoU","colab":{"base_uri":"https://localhost:8080/","height":673},"executionInfo":{"status":"error","timestamp":1618140775964,"user_tz":-480,"elapsed":78243,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}},"outputId":"19633441-4783-4736-953d-07c1dc781516"},"source":["history = model.fit(\n","            x=train_x,\n","            y=train_y,\n","            batch_size=400,\n","            epochs=20,\n","            validation_data=(test_x, test_y),\n","            # callbacks=[earlystop],\n","        )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","63/63 [==============================] - 13s 168ms/step - loss: 0.7000 - acc: 0.5119 - val_loss: 0.6908 - val_acc: 0.5086\n","Epoch 2/20\n","63/63 [==============================] - 10s 157ms/step - loss: 0.6936 - acc: 0.5430 - val_loss: 0.6875 - val_acc: 0.5460\n","Epoch 3/20\n","63/63 [==============================] - 10s 157ms/step - loss: 0.6612 - acc: 0.6054 - val_loss: 0.5989 - val_acc: 0.6692\n","Epoch 4/20\n","63/63 [==============================] - 10s 156ms/step - loss: 0.4457 - acc: 0.8055 - val_loss: 0.3713 - val_acc: 0.8438\n","Epoch 5/20\n","63/63 [==============================] - 10s 157ms/step - loss: 0.2732 - acc: 0.9022 - val_loss: 0.3511 - val_acc: 0.8627\n","Epoch 6/20\n","63/63 [==============================] - 10s 157ms/step - loss: 0.1963 - acc: 0.9347 - val_loss: 0.3159 - val_acc: 0.8672\n","Epoch 7/20\n","63/63 [==============================] - 10s 157ms/step - loss: 0.1658 - acc: 0.9480 - val_loss: 0.3330 - val_acc: 0.8613\n","Epoch 8/20\n","45/63 [====================>.........] - ETA: 2s - loss: 0.1451 - acc: 0.9549"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-a0ab7d855d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# callbacks=[earlystop],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"zPnpaWf_ne6K"},"source":["from tensorflow.keras.models import load_model\n","\n","# 保存模型\n","# model.save(\"10in_32unit_temp_res.h5\")\n","# del model  # deletes the existing model\n","# 导入已经训练好的模型\n","# model = load_model(\"my_model.h5\")\n","## 保存训练好的Tokenizer，和导入\n","import pickle\n","\n","# saving\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/tokenizer/49in_SST.pickle\", \"wb\") as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":743},"id":"dCKauqOfne6L","executionInfo":{"status":"error","timestamp":1618040790731,"user_tz":-480,"elapsed":799,"user":{"displayName":"柳箜铭","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64","userId":"16745569133448555194"}},"outputId":"0dfa94e3-8a59-4c23-c3f7-8d9b7a22d876"},"source":["loss, accuracy = model.evaluate(x=[test_x, test_x], y=test_y, verbose=0)\n","print(loss)\n","print(accuracy)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-107-986df98acfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_15 expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 49) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 49) dtype=int32>]\n"]}]},{"cell_type":"markdown","metadata":{"id":"GkkdvFiAne6M"},"source":["### google"]},{"cell_type":"code","metadata":{"id":"dk2R4i81ne6M"},"source":["def load_google():\n","    Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n","        r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n","    )\n","\n","    vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n","\n","    # word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n","    embeddings_index = {}  # 初始化`[word : vector]`字典\n","\n","    for i in range(len(vocab_list)):\n","        # print(i)\n","        word = vocab_list[i]  # 每个词语\n","        # word_index[word] = i + 1 # 词语：序号\n","        embeddings_index[word] = Word2VecModel.wv[word]  # 词语：词向量\n","        # embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵\n","    return embeddings_index\n","\n","\n","def load_fasttext_embeddings():\n","    glove_dir = r\"E:\\CS\\MLT\\glove.6B\"\n","    embeddings_index = {}\n","    f = open(os.path.join(glove_dir, \"glove.6B.50d.txt\"), encoding=\"utf-8\")\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype=\"float32\")\n","        embeddings_index[word] = coefs\n","    f.close()\n","    print(\"Found %s word vectors.\" % len(embeddings_index))\n","    return embeddings_index\n","\n","\n","def create_embeddings_matrix(embeddings_index, vocabulary, embedding_dim=100):\n","    embeddings_matrix = np.random.rand(len(vocabulary) + 1, embedding_dim)\n","    for i, word in enumerate(vocabulary):\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embeddings_matrix[i] = embedding_vector\n","    print(\"Matrix shape: {}\".format(embeddings_matrix.shape))\n","    return embeddings_matrix\n","\n","\n","embeddings_index = load_google()\n","embeddings_matrix = create_embeddings_matrix(embeddings_index, word_index, 300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANOlCJ1tne6P"},"source":["import gensim\n","\n","Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n","    r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n",")\n","\n","vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n","\n","word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n","word_vector = {}  # 初始化`[word : vector]`字典\n","\n","for i in range(len(vocab_list)):\n","    # print(i)\n","    word = vocab_list[i]  # 每个词语\n","    #     word_index[word] = i + 1 # 词语：序号\n","    #     word_vector[word] = Word2VecModel.wv[word] # 词语：词向量\n","    embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵"],"execution_count":null,"outputs":[]}]}