{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "name": "BiLSTM_IMDB.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwcXt_Kcne5N"
   },
   "source": [
    "# BiLSTM_SST\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tq9imcf0ne5o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618979811459,
     "user_tz": -480,
     "elapsed": 3782,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Add,\n",
    "    Lambda,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    LSTM,\n",
    "    Bidirectional\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.backend import l2_normalize\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from IPython.display import SVG"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q_GjM47tne5r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618979811460,
     "user_tz": -480,
     "elapsed": 2736,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "def ModiData(obj_df):\n",
    "    obj_df = obj_df[obj_df[\"label\"] != 2]\n",
    "    # obj_df[\"label\"] = obj_df[\"label\"].astype(string)\n",
    "    obj_df.label = obj_df.label.replace(0, \"neg\")\n",
    "    obj_df.label = obj_df.label.replace(1, \"neg\")\n",
    "    obj_df.label = obj_df.label.replace(3, \"pos\")\n",
    "    obj_df.label = obj_df.label.replace(4, \"pos\")\n",
    "    obj_df = obj_df.fillna(0)\n",
    "    # obj_df[\"label\"] = obj_df[\"label\"].astype(int)\n",
    "    return obj_df\n",
    "\n",
    "\n",
    "def clean_line(line):\n",
    "    # split into tokens by white space\n",
    "    tokens = line.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding=\"post\")\n",
    "    return padded"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EUzER7CyolZy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618979823846,
     "user_tz": -480,
     "elapsed": 5191,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"../IMDB/train.csv\",\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"../IMDB/test.csv\",\n",
    ")\n",
    "\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hoxxs-jane5t",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618979831659,
     "user_tz": -480,
     "elapsed": 9980,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "# train_df = ModiData(train_df)\n",
    "# # dev_df = ModiData(dev_df)\n",
    "# test_df = ModiData(test_df)\n",
    "\n",
    "train_x = train_df.text.tolist()\n",
    "train_y = train_df.label\n",
    "# dev_x = dev_df.text.tolist()\n",
    "# dev_y = dev_df.label\n",
    "test_x = test_df.text.tolist()\n",
    "test_y = test_df.label\n",
    "\n",
    "\n",
    "max_len = 200\n",
    "# tokenizer = create_tokenizer(train_x)\n",
    "with open(\"../tokenizer/200in_IMDB.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_index = tokenizer.word_index\n",
    "train_x = encode_text(tokenizer, train_x, max_len)\n",
    "# dev_x = encode_text(tokenizer, dev_x, max_len)\n",
    "test_x = encode_text(tokenizer, test_x, max_len)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train_y).reshape(-1, 1)\n",
    "# dev_y = le.transform(dev_y).reshape(-1, 1)\n",
    "test_y = le.transform(test_y).reshape(-1, 1)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtoxFTHhne5v"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b8g1hAT9ne5w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618982080903,
     "user_tz": -480,
     "elapsed": 1139,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "def get_embeddings_layer(name, max_len, trainable):\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=len(word_index)+1,\n",
    "        output_dim=50,\n",
    "        input_length=max_len,\n",
    "        # weights=[embeddings_matrix],\n",
    "        trainable=trainable,\n",
    "        name=name,\n",
    "    )\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def get_LSTM(max_len):\n",
    "    embeddings_layer = get_embeddings_layer(\n",
    "       \"embeddings_layer\", max_len, trainable=True\n",
    "    )\n",
    "\n",
    "    # dynamic channel\n",
    "    in_layer = Input(shape=(max_len,), dtype=\"int32\", name=\"input\")\n",
    "    layer = embeddings_layer(in_layer)\n",
    "    \n",
    "    layer = Bidirectional(LSTM(256,return_sequences=True))(layer)\n",
    "    layer = Bidirectional(LSTM(256))(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(64, activation=\"relu\", name=\"FC1\")(layer)\n",
    "    # layer = Dropout(0.5)(layer)\n",
    "\n",
    "    o = Dense(1, activation=\"sigmoid\", name=\"output\",)(layer)\n",
    "\n",
    "    model = Model(inputs=in_layer, outputs=o)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n19GzqOvne5z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618982081502,
     "user_tz": -480,
     "elapsed": 831,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"val_loss\") <= 0.335:\n",
    "            print(\"\\nReached 0.32 loss\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "beststop = myCallback()\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0.001)\n",
    "checkpointer = ModelCheckpoint(filepath=\"./weights.hdf5\", verbose=1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2_NteEQzne50",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618982082626,
     "user_tz": -480,
     "elapsed": 901,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    }
   },
   "source": [
    "def TrainModel(num):\n",
    "    while num > 0:\n",
    "        model = get_LSTM(max_len)\n",
    "        # model.summary()\n",
    "        history = model.fit(\n",
    "            x=train_x,\n",
    "            y=train_y,\n",
    "            batch_size=400,\n",
    "            epochs=5,\n",
    "            validation_data=(test_x, test_y),\n",
    "            callbacks=[beststop],\n",
    "        )\n",
    "        if history.history[\"val_acc\"][-1] >= 0.86:\n",
    "            save_name = (\n",
    "                \"../Model/BiLSTM_IMDB/\"\n",
    "                + str(history.history[\"val_loss\"][-1])[2:6]\n",
    "                + \"_\"\n",
    "                + str(history.history[\"val_acc\"][-1])[2:6]\n",
    "                + \".hdf5\"\n",
    "            )\n",
    "            num -= 1\n",
    "            model.save(save_name)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgZP84VHne53",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618994304871,
     "user_tz": -480,
     "elapsed": 12221615,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "c3730c77-eaff-4e94-bda9-06633cfcc052"
   },
   "source": [
    "TrainModel(10)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 303ms/step - loss: 0.6957 - acc: 0.5356 - val_loss: 0.5266 - val_acc: 0.7795\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 281ms/step - loss: 0.5128 - acc: 0.7784 - val_loss: 0.4806 - val_acc: 0.7966\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 282ms/step - loss: 0.3898 - acc: 0.8405 - val_loss: 0.4002 - val_acc: 0.8291\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.2423 - acc: 0.9116 - val_loss: 0.4788 - val_acc: 0.8216\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1668 - acc: 0.9433 - val_loss: 0.4264 - val_acc: 0.8215\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 296ms/step - loss: 0.6915 - acc: 0.5229 - val_loss: 0.6826 - val_acc: 0.5932\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.6204 - acc: 0.6425 - val_loss: 0.4349 - val_acc: 0.8224\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.3453 - acc: 0.8676 - val_loss: 0.4275 - val_acc: 0.8341\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.1641 - acc: 0.9436 - val_loss: 0.3809 - val_acc: 0.8532\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0689 - acc: 0.9785 - val_loss: 0.5256 - val_acc: 0.8343\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6808 - acc: 0.5493 - val_loss: 0.6068 - val_acc: 0.6758\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.4435 - acc: 0.7972 - val_loss: 0.3353 - val_acc: 0.8594\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.1484 - acc: 0.9490 - val_loss: 0.3889 - val_acc: 0.8470\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0731 - acc: 0.9784 - val_loss: 0.5414 - val_acc: 0.8432\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.0364 - acc: 0.9906 - val_loss: 0.5987 - val_acc: 0.8333\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 296ms/step - loss: 0.7087 - acc: 0.5326 - val_loss: 0.5568 - val_acc: 0.7298\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.5200 - acc: 0.7740 - val_loss: 0.4489 - val_acc: 0.8022\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2423 - acc: 0.9078 - val_loss: 0.3738 - val_acc: 0.8426\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.1231 - acc: 0.9622 - val_loss: 0.4433 - val_acc: 0.8473\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.0671 - acc: 0.9815 - val_loss: 0.5791 - val_acc: 0.8317\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 300ms/step - loss: 0.6965 - acc: 0.5384 - val_loss: 0.6785 - val_acc: 0.5505\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.6206 - acc: 0.6389 - val_loss: 0.6637 - val_acc: 0.6812\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.5134 - acc: 0.7476 - val_loss: 0.4709 - val_acc: 0.8077\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2679 - acc: 0.8954 - val_loss: 0.3967 - val_acc: 0.8316\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.1369 - acc: 0.9553 - val_loss: 0.4336 - val_acc: 0.8453\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 302ms/step - loss: 0.6848 - acc: 0.5581 - val_loss: 0.6492 - val_acc: 0.5998\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.5108 - acc: 0.7458 - val_loss: 0.3843 - val_acc: 0.8412\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2296 - acc: 0.9169 - val_loss: 0.3786 - val_acc: 0.8385\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.1228 - acc: 0.9626 - val_loss: 0.4169 - val_acc: 0.8412\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.0664 - acc: 0.9824 - val_loss: 0.5154 - val_acc: 0.8244\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 296ms/step - loss: 0.6698 - acc: 0.5540 - val_loss: 0.4583 - val_acc: 0.7892\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.3484 - acc: 0.8629 - val_loss: 0.3380 - val_acc: 0.8614\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.1404 - acc: 0.9512 - val_loss: 0.4487 - val_acc: 0.8547\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 286ms/step - loss: 0.0660 - acc: 0.9808 - val_loss: 0.5246 - val_acc: 0.8396\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.0427 - acc: 0.9875 - val_loss: 0.5541 - val_acc: 0.8346\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 296ms/step - loss: 0.7050 - acc: 0.5303 - val_loss: 0.6535 - val_acc: 0.6230\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.5360 - acc: 0.7349 - val_loss: 0.5097 - val_acc: 0.7804\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.4970 - acc: 0.7869 - val_loss: 0.4431 - val_acc: 0.8076\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2978 - acc: 0.8801 - val_loss: 0.5634 - val_acc: 0.7942\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.2807 - acc: 0.9067 - val_loss: 0.4664 - val_acc: 0.8215\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6867 - acc: 0.5475 - val_loss: 0.6767 - val_acc: 0.6734\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.3738 - acc: 0.8491 - val_loss: 0.3576 - val_acc: 0.8449\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.1353 - acc: 0.9539 - val_loss: 0.3675 - val_acc: 0.8587\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0589 - acc: 0.9820 - val_loss: 0.5020 - val_acc: 0.8414\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.0577 - acc: 0.9822 - val_loss: 0.5157 - val_acc: 0.8178\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 296ms/step - loss: 0.6815 - acc: 0.5559 - val_loss: 0.6019 - val_acc: 0.6584\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.4638 - acc: 0.7844 - val_loss: 0.4323 - val_acc: 0.7994\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 19s 295ms/step - loss: 0.2043 - acc: 0.9258 - val_loss: 0.3729 - val_acc: 0.8433\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 294ms/step - loss: 0.1055 - acc: 0.9670 - val_loss: 0.4471 - val_acc: 0.8332\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 288ms/step - loss: 0.0560 - acc: 0.9845 - val_loss: 0.6228 - val_acc: 0.8348\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 21s 294ms/step - loss: 0.6861 - acc: 0.5365 - val_loss: 0.5796 - val_acc: 0.7022\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.4634 - acc: 0.8079 - val_loss: 0.3771 - val_acc: 0.8404\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.2477 - acc: 0.9113 - val_loss: 0.5037 - val_acc: 0.7947\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1849 - acc: 0.9357 - val_loss: 0.4152 - val_acc: 0.8306\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0960 - acc: 0.9706 - val_loss: 0.4631 - val_acc: 0.8431\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 294ms/step - loss: 0.6811 - acc: 0.5507 - val_loss: 0.4302 - val_acc: 0.8204\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3518 - acc: 0.8641 - val_loss: 0.5106 - val_acc: 0.7616\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2534 - acc: 0.9068 - val_loss: 0.3660 - val_acc: 0.8513\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1265 - acc: 0.9584 - val_loss: 0.4343 - val_acc: 0.8412\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3722 - acc: 0.8016 - val_loss: 0.6922 - val_acc: 0.5132\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6925 - acc: 0.5433 - val_loss: 0.6372 - val_acc: 0.6352\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.4289 - acc: 0.8101 - val_loss: 0.4091 - val_acc: 0.8142\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.2308 - acc: 0.9197 - val_loss: 0.4140 - val_acc: 0.8198\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.1163 - acc: 0.9636 - val_loss: 0.4794 - val_acc: 0.8387\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0490 - acc: 0.9866 - val_loss: 0.5874 - val_acc: 0.8278\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 294ms/step - loss: 0.6920 - acc: 0.5413 - val_loss: 0.4860 - val_acc: 0.7832\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.3414 - acc: 0.8661 - val_loss: 0.3323 - val_acc: 0.8584\n",
      "\n",
      "Reached 0.32 loss\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 294ms/step - loss: 0.6931 - acc: 0.5402 - val_loss: 0.6810 - val_acc: 0.5472\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.5858 - acc: 0.6877 - val_loss: 0.5662 - val_acc: 0.7119\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.3384 - acc: 0.8571 - val_loss: 0.4245 - val_acc: 0.8407\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1810 - acc: 0.9391 - val_loss: 0.4038 - val_acc: 0.8392\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0832 - acc: 0.9757 - val_loss: 0.5124 - val_acc: 0.8485\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6856 - acc: 0.5570 - val_loss: 0.4992 - val_acc: 0.7797\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3413 - acc: 0.8663 - val_loss: 0.4056 - val_acc: 0.8538\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1649 - acc: 0.9457 - val_loss: 0.3725 - val_acc: 0.8456\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0859 - acc: 0.9736 - val_loss: 0.5100 - val_acc: 0.8312\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 0.0446 - acc: 0.9880 - val_loss: 0.5172 - val_acc: 0.8285\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 294ms/step - loss: 0.6874 - acc: 0.5577 - val_loss: 0.5063 - val_acc: 0.7543\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.4216 - acc: 0.8250 - val_loss: 0.4141 - val_acc: 0.8183\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.2024 - acc: 0.9272 - val_loss: 0.3959 - val_acc: 0.8531\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0829 - acc: 0.9762 - val_loss: 0.5129 - val_acc: 0.8311\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0480 - acc: 0.9866 - val_loss: 0.5894 - val_acc: 0.8215\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 294ms/step - loss: 0.6772 - acc: 0.5487 - val_loss: 0.4634 - val_acc: 0.7924\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.3504 - acc: 0.8576 - val_loss: 0.3282 - val_acc: 0.8667\n",
      "\n",
      "Reached 0.32 loss\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6684 - acc: 0.5788 - val_loss: 0.4404 - val_acc: 0.8068\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3752 - acc: 0.8448 - val_loss: 0.5486 - val_acc: 0.7717\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.2607 - acc: 0.9012 - val_loss: 0.4564 - val_acc: 0.8458\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1103 - acc: 0.9658 - val_loss: 0.4480 - val_acc: 0.8452\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.0542 - acc: 0.9852 - val_loss: 0.5405 - val_acc: 0.8290\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 293ms/step - loss: 0.6658 - acc: 0.5744 - val_loss: 0.4117 - val_acc: 0.8240\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3260 - acc: 0.8724 - val_loss: 0.3615 - val_acc: 0.8539\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.1527 - acc: 0.9475 - val_loss: 0.3792 - val_acc: 0.8488\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0760 - acc: 0.9778 - val_loss: 0.4950 - val_acc: 0.8289\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0418 - acc: 0.9884 - val_loss: 0.5056 - val_acc: 0.8206\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 295ms/step - loss: 0.6749 - acc: 0.5657 - val_loss: 0.4914 - val_acc: 0.7640\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 283ms/step - loss: 0.3679 - acc: 0.8506 - val_loss: 0.4032 - val_acc: 0.8282\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.1870 - acc: 0.9347 - val_loss: 0.4258 - val_acc: 0.8360\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 19s 302ms/step - loss: 0.1035 - acc: 0.9664 - val_loss: 0.5359 - val_acc: 0.8272\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 19s 295ms/step - loss: 0.0538 - acc: 0.9852 - val_loss: 0.6098 - val_acc: 0.8091\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 24s 315ms/step - loss: 0.6790 - acc: 0.5547 - val_loss: 0.4537 - val_acc: 0.7966\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 18s 295ms/step - loss: 0.3489 - acc: 0.8601 - val_loss: 0.3961 - val_acc: 0.8323\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 19s 295ms/step - loss: 0.2007 - acc: 0.9315 - val_loss: 0.3999 - val_acc: 0.8451\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.1069 - acc: 0.9654 - val_loss: 0.4446 - val_acc: 0.8540\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.0695 - acc: 0.9808 - val_loss: 0.5289 - val_acc: 0.8460\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 300ms/step - loss: 0.6858 - acc: 0.5496 - val_loss: 0.6464 - val_acc: 0.6402\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 19s 295ms/step - loss: 0.5487 - acc: 0.7320 - val_loss: 0.3948 - val_acc: 0.8295\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.2088 - acc: 0.9215 - val_loss: 0.3642 - val_acc: 0.8561\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 18s 287ms/step - loss: 0.1042 - acc: 0.9694 - val_loss: 0.4674 - val_acc: 0.8434\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0441 - acc: 0.9880 - val_loss: 0.6413 - val_acc: 0.8406\n",
      "Epoch 1/5\n",
      "63/63 [==============================] - 22s 301ms/step - loss: 0.6888 - acc: 0.5615 - val_loss: 0.5353 - val_acc: 0.7475\n",
      "Epoch 2/5\n",
      "44/63 [===================>..........] - ETA: 4s - loss: 0.4595 - acc: 0.8025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-b1c8d42a18ee>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mTrainModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-8-d4b3982438e9>\u001B[0m in \u001B[0;36mTrainModel\u001B[1;34m(num)\u001B[0m\n\u001B[0;32m      9\u001B[0m             \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbeststop\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m         )\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"val_acc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[1;36m0.86\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1098\u001B[0m                 _r=1):\n\u001B[0;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1100\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1101\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"xla\"\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    853\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    854\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 855\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    856\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    857\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m-> 2943\u001B[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   2944\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2945\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1917\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1918\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1919\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1921\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    558\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 560\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    561\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32mD:\\programs\\anaconda\\envs\\tf1.14.0\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 60\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DrRb6_yVne6K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1618141132761,
     "user_tz": -480,
     "elapsed": 2007,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "ff445296-462a-47c6-b37b-9e678504ce97"
   },
   "source": [
    "# del model\n",
    "model = get_LSTM(max_len)\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embeddings_layer (Embedding) (None, 200, 50)           691800    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 200, 512)          628736    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,928,345\n",
      "Trainable params: 2,928,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zdN3TkmwnkoU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1618141233011,
     "user_tz": -480,
     "elapsed": 100055,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "bface825-b09c-4b1d-8e3c-f034b3c753fc"
   },
   "source": [
    "history = model.fit(\n",
    "            x=train_x,\n",
    "            y=train_y,\n",
    "            batch_size=400,\n",
    "            epochs=20,\n",
    "            validation_data=(test_x, test_y),\n",
    "            # callbacks=[earlystop],\n",
    "        )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 27s 366ms/step - loss: 0.6650 - acc: 0.5623 - val_loss: 0.4676 - val_acc: 0.7945\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 22s 347ms/step - loss: 0.3394 - acc: 0.8597 - val_loss: 0.3259 - val_acc: 0.8616\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 22s 348ms/step - loss: 0.2247 - acc: 0.9183 - val_loss: 0.3265 - val_acc: 0.8590\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 22s 348ms/step - loss: 0.1644 - acc: 0.9449 - val_loss: 0.3649 - val_acc: 0.8609\n",
      "Epoch 5/20\n",
      "21/63 [=========>....................] - ETA: 10s - loss: 0.1395 - acc: 0.9526"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-a0ab7d855d9d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m400\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m             \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m             \u001B[0;31m# callbacks=[earlystop],\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1098\u001B[0m                 _r=1):\n\u001B[1;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    853\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 855\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    856\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    857\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 2943\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   2944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2945\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1917\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1918\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1919\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1921\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    558\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 560\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    561\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    562\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zPnpaWf_ne6K"
   },
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 保存模型\n",
    "# model.save(\"10in_32unit_temp_res.h5\")\n",
    "# del model  # deletes the existing model\n",
    "# 导入已经训练好的模型\n",
    "# model = load_model(\"my_model.h5\")\n",
    "## 保存训练好的Tokenizer，和导入\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"/content/drive/MyDrive/Sentiment Analysis/tokenizer/49in_SST.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "dCKauqOfne6L",
    "executionInfo": {
     "status": "error",
     "timestamp": 1618040790731,
     "user_tz": -480,
     "elapsed": 799,
     "user": {
      "displayName": "柳箜铭",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwCICr9ID5QfKQ8gBpGLnwTSXha1wSAt2FGshyhQ=s64",
      "userId": "16745569133448555194"
     }
    },
    "outputId": "0dfa94e3-8a59-4c23-c3f7-8d9b7a22d876"
   },
   "source": [],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-107-986df98acfc1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtest_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_x\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1387\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1388\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1389\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1390\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1391\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    860\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    861\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 862\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    863\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    864\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2939\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[0;32m-> 2941\u001B[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0m\u001B[1;32m   2942\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3356\u001B[0m               call_context_key in self._function_cache.missed):\n\u001B[1;32m   3357\u001B[0m             return self._define_function_with_shape_relaxation(\n\u001B[0;32m-> 3358\u001B[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0m\u001B[1;32m   3359\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_define_function_with_shape_relaxation\u001B[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001B[0m\n\u001B[1;32m   3278\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3279\u001B[0m     graph_function = self._create_graph_function(\n\u001B[0;32m-> 3280\u001B[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001B[0m\u001B[1;32m   3281\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marg_relaxed\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mrank_only_cache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3282\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3204\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3205\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3206\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3207\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3208\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    632\u001B[0m             \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 977\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    978\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1183 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_15 expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 49) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 49) dtype=int32>]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkkdvFiAne6M"
   },
   "source": [
    "### google"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dk2R4i81ne6M"
   },
   "source": [
    "def load_google():\n",
    "    Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n",
    "    )\n",
    "\n",
    "    vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n",
    "\n",
    "    # word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "    embeddings_index = {}  # 初始化`[word : vector]`字典\n",
    "\n",
    "    for i in range(len(vocab_list)):\n",
    "        # print(i)\n",
    "        word = vocab_list[i]  # 每个词语\n",
    "        # word_index[word] = i + 1 # 词语：序号\n",
    "        embeddings_index[word] = Word2VecModel.wv[word]  # 词语：词向量\n",
    "        # embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def load_fasttext_embeddings():\n",
    "    glove_dir = r\"E:\\CS\\MLT\\glove.6B\"\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(glove_dir, \"glove.6B.50d.txt\"), encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def create_embeddings_matrix(embeddings_index, vocabulary, embedding_dim=100):\n",
    "    embeddings_matrix = np.random.rand(len(vocabulary) + 1, embedding_dim)\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embeddings_matrix[i] = embedding_vector\n",
    "    print(\"Matrix shape: {}\".format(embeddings_matrix.shape))\n",
    "    return embeddings_matrix\n",
    "\n",
    "\n",
    "embeddings_index = load_google()\n",
    "embeddings_matrix = create_embeddings_matrix(embeddings_index, word_index, 300)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ANOlCJ1tne6P"
   },
   "source": [
    "import gensim\n",
    "\n",
    "Word2VecModel = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    r\"E:\\CS\\MLT\\GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")\n",
    "\n",
    "vocab_list = [word for word, Vocab in Word2VecModel.wv.vocab.items()]  # 存储 所有的 词语\n",
    "\n",
    "word_index = {\" \": 0}  # 初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。\n",
    "word_vector = {}  # 初始化`[word : vector]`字典\n",
    "\n",
    "for i in range(len(vocab_list)):\n",
    "    # print(i)\n",
    "    word = vocab_list[i]  # 每个词语\n",
    "    #     word_index[word] = i + 1 # 词语：序号\n",
    "    #     word_vector[word] = Word2VecModel.wv[word] # 词语：词向量\n",
    "    embeddings_matrix[i + 1] = Word2VecModel.wv[word]  # 词向量矩阵"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
